#+TITLE:bio events 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----

* setup
- The idea is to house a complete data and document compendium as an R package
- Using the template from https://github.com/jhollist/manuscriptPackage

* perhaps submit a data descriptor paper?
http://www.biomedcentral.com/bmcresnotes/authors/instructions/datanote
~/Dropbox/tools/LaTeX templates/Biomed/biomed_2015/bmc_template
* COMMENT conceptual-diagram-code
#+name:conceptual-diagram
#+begin_src R :session *R* :tangle inst/doc/conceptual-diagram.R :exports none :eval yes
  #### name:conceptual-diagram ####
  setwd("~/data/BiosmokeValidatedEvents/inst/doc")
  library(disentangle)
  library(stringr)
  dat <- read.csv("conceptual-diagram.csv", stringsAsFactor = F)
  str(dat)
  flowchart <- newnode_df(
    indat = dat
    ,
    names_col = "name"
    ,
    in_col = "inputs"
    ,
    out_col = "outputs"
    ,
    clusters_col= "group"
    ,
    desc_col="description"
    )
  
  sink("fileTransformations.dot")
  cat(flowchart)
  sink()
  system("dot -Tpdf fileTransformations.dot -o fileTransformations.pdf")
  
#+end_src

#+RESULTS: conceptual-diagram
: 0

* reference review
media/external/u3171954-H/My%20Documents/projects/1.302%20Biomass/analysis/exposures/event%20validation/Archive_20100609/REFS
* metadata
** Methods
*** COMMENT methods-code
#+name:methods
#+begin_src R :session *R* :tangle no :exports none :eval yes
  #### name:methods ####
  if(exists('ch'))   dbDisconnect(ch)
  etl <- "load"
  library(rpostgrestools)
  ch <- connect2postgres2("data_inventory_hanigan_dev4")
  setwd("~/data/bio_validated_bushfire_events")
  dir()
  dset <- "bio_validated_bushfire_events"
  
  pid <- dbGetQuery(ch,
  #cat(                  
  sprintf("select project_id
  from dataset
  where shortname = '%s'",
                    dset
                    )
  )
  pid
  
  prj <- dbGetQuery(ch,
  sprintf("select *
  from project
  where id = %s",
                    pid
             )
  )
  prj <- as.matrix(t(prj))
  if(etl == "extract"){
  write.csv(prj, "project.csv", row.names=T)
  } 
  #### edit this ####
  prj  <- read.csv("project.csv", stringsAsFactor = F)
  prj 
  prj <- prj[-which(prj[,2] == ''),]
  input <- prj[,2]
  nums <- as.numeric(input)
  
  replace  <-   which(is.na(nums))
  dont_replace  <-  which(!is.na(nums))
  
  rplace <- gsub("NA", "", paste("'", paste(input[replace], "'", sep = ""), sep = ""))
  rplace_df <- as.data.frame(rbind(
  cbind(dont_replace, input[dont_replace])
        ,
  cbind(replace, rplace)
  ))
  
  rplace_df <- cbind(rplace_df, prj[,1])
  txt <- paste(apply(rplace_df[,3:2], 1, paste, collapse = " = "), sep = "", collapse = ", ")
  cat(txt)
  # TODO don;t do empty strings  
  dbSendQuery(ch,
  #cat(            
  sprintf("UPDATE project
     SET %s
   WHERE id = %s",  txt, pid)
  )
  
  ## UPDATE project
  ##    SET id=?, title=?, abstract=?, studyareadescription=?, personnel=?, 
  ##        funding=?, personnel_owner_organisationname=?, personnel_data_owner=?
  ##  WHERE <condition>;
  
  
  ## dbSendQuery(ch, "UPDATE dataset
  ## SET method_steps='
  ## Step 1: acquire the smoke pollution data from State Governments.
  ## Step 2: load into a postgres database.
  
  ## See /media/Seagate Expansion Drive/u3171954-H/My Documents/projects/1.302 Biomass/analysis/exposures/event validation/impute
  ## which I need to compare with
  ## /media/Seagate Expansion Drive/ivan_acer/projects/1.302 Biomass/analysis/exposures/event validation/versions/2012-01-12/impute
  
  ## '
  ## WHERE shortname = 'bio_validated_bushfire_events';
  ## ")
  
#+end_src

#+RESULTS: methods


* COMMENT get-data-delphe-code
#+name:get-data-delphe
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:get-data-delphe
  require(swishdbtools)

  ch <- connect2postgres2("delphe")
  
  tbls <- c("bio_events.tblreferences",
  "bio_events.tblevents",
  "bio_events.dust_event_records",
  "bio_events.dust_event_records2")
  dir()
  for(tb in tbls)
    {
      #tb  <- tbls[1]
      print(tb)
      df <- sql_subset(ch, tb, eval = T)
      #str(df)
      write.csv(df, paste(tb, ".csv", sep = ""), row.names = FALSE, na = "")
    }
  
#+end_src

