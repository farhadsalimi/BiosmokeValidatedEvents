#+TITLE:bio events index
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----

* TODO-list
** admin users sign up
ssh in 
postgres
psql ewedb
select registration_key from auth_user where first_name = 'Ivan' and last_name = 'Hanigan';
Pending
update auth_user set registration_key = '' where first_name = 'Ivan' and last_name = 'Hanigan';
rm?
ewedb=# delete from auth_user where first_name = 'ivan';
DELETE 1

** TODO grant comments

* setup
- The idea is to link a R package with a portable web2py database, online server version and published manuscript 

* R code for methods
** method steps
*** step1 source air pollution data and load to a postgres database

*** step2 source and load spatial data representing the city boundaries
*** step3 Calculate a network average
**** main
#+begin_src R :session *R* :tangle inst/doc/main.R :exports none :padline no :eval no
  #################################################################
  projectdir <- "~/projects/biomass_smoke_and_human_health/BiosmokeValidatedEvents/inst/doc"
  setwd(projectdir)
  library(rpostgrestools)
  # you will need to request username and password
  ch <- connect2postgres2("ewedb_staging")
  
#+end_src
**** main setup list of towns
#+begin_src R :session *R* :tangle inst/doc/main.R :exports none :padline no :eval no
    
  
  #################################################################
  towns <- c("PERTH", "Sydney","Illawarra","Lower Hunter","Hobart","Launceston")  
  
#+end_src

#+RESULTS:
| PERTH        |
| Sydney       |
| Illawarra    |
| Lower Hunter |
| Hobart       |
| Launceston   |

**** main setup list of pollutants
#+begin_src R :session *R* :tangle inst/doc/main.R :exports none :padline no :eval no
    
  
  #################################################################
  
  # list pollutants
  polls <- cbind(c("sulphurdioxide_pphm","nitrogendioxide_pphm",
                   "carbonmonoxide_ppm","ozone_pphm","particulatematter10um_ugm3",
                   "nephelometer_bsp", "particulatematter2_5um_ugm3", "nitricoxide_pphm"),
                 c("so2_max","no2_max","co_max" ,    "o3_max", "pm10_av", "bsp_max",
                   "pm25_av",  "no_max"),
                 c("SO2","NO2","CO","O3","PM10","BSP","PM25","NO")
                 )
  polls
  # select on for this run
  poll_i <- 7
  (poll <- polls[poll_i,3])
  (pollutant <- polls[poll_i,2])
  
#+end_src

#+RESULTS:
: o3_max

**** func mindates_pollutant-code
#+name:mindates_pollutant
#+begin_src R :session *R* :tangle R/mindates_pollutant.R :exports none :padline no :eval yes
  #' @name mindates_pollutant
  #' @title Minimum Date a Pollutant is observed from 
  #' @param town the Biomass Study Town in question
  #' @param pollutant you got it
  #' @return text for a SQL query
  
  
  mindates_pollutant <- function(
    town = "perth"
    ,
    pollutant = "pm10_av"
    ){
    if(length(grep("_av$", pollutant)) > 0){
      pollutant_label <- gsub("_av$", "_avg", pollutant)
    } else {
      pollutant_label <- pollutant
    }
  txt <- paste("select t1.r2, min(t1.date) as min",pollutant_label,"
        from (
          SELECT combined_pollutants2.r2, date, avg(",pollutant,") as ", pollutant_label, "
          FROM biosmoke_pollution.combined_pollutants 
          join 
          (
                  select t1.site,t1.region as r2, t2.studysite as region
                  from biosmoke_pollution.pollution_stations_combined_final t1,
                  biosmoke_spatial.study_slas_01 t2
                  where st_intersects(t1.geom,t2.geom)
                    and lower(
        case when t2.studysite like \'Sydney%\' then \'Sydney\' else t2.studysite end 
                     ) = \'",tolower(town),"\'
                  order by studysite
          ) combined_pollutants2 
          on biosmoke_pollution.combined_pollutants.site = combined_pollutants2.site
          where ",pollutant," is not null
          group by r2,date
          order by r2, date) t1
        group by t1.r2
    ", sep = "")
  #cat(txt)
    return(txt)
  }
  
#+end_src

#+RESULTS: mindates_pollutant
**** func all_stations_all_dates-code
#+name:all_stations_all_dates
#+begin_src R :session *R* :tangle R/all_stations_all_dates.R :exports none :padline no :eval yes
  #' @name all_stations_all_dates
  #' @title All Stations, All Dates
  #' @param town Biomass Study area
  #' @param pollutant you got it
  #' @return text for a query
  all_stations_all_dates <- function(town, pollutant){
  if(length(grep("_av$", pollutant)) > 0){
    pollutant_label <- gsub("_av$", "", pollutant)
  } else {
    pollutant_label <- pollutant
  }
  
  txt <- paste("
  select site as station, date 
  into biosmoke_pollution.stationdates_",town,"_",pollutant_label,"
  from
  (select distinct biosmoke_pollution.combined_pollutants.site 
  from biosmoke_pollution.combined_pollutants
  join
          (
          select t1.site,t2.studysite as region
          from biosmoke_pollution.pollution_stations_combined_final t1 , 
          biosmoke_spatial.study_slas_01 t2
          where st_intersects(t1.geom,t2.geom) and upper(t2.studysite) like '",toupper(town),"%'
          order by studysite
          ) combined_pollutants2
  on biosmoke_pollution.combined_pollutants.site=combined_pollutants2.site
  ) sites,
  (select * from alldates_",pollutant_label,"_",town,") dates
  ",sep="")
  
  # cat(txt)
  return(txt)
  }
#+end_src

#+RESULTS: all_stations_all_dates

**** missing dates are added for completeness
#+begin_src R :session *R* :tangle inst/doc/01_prepare_dates.R :exports none :padline no :eval no
  #################################################################
  # to identify sites to be included need to know how many missing days.
  # first create complete set of statoiondates for the sites per town
  # this was set up after assessing the time series for completeness.  
  # Perth and Launceston PM10 mindates were altered 
  matrix(towns)
  ## [1,] "PERTH"       
  ## [2,] "Sydney"      
  ## [3,] "Illawarra"   
  ## [4,] "Lower Hunter"
  ## [5,] "Hobart"      
  ## [6,] "Launceston"  
  
  # note o3 only done for towns[1:4]
  
  for(town in towns){
  #town  <- towns[2]
  # housekeeping code to begin
  # NB the updates made in 2015 mean that the 2007 end date is no longer
  # correct in sydney
  if(town == "Sydney"){
      maxdate_selected  <- as.Date('2014-12-31')
  }  else {
      maxdate_selected  <- as.Date('2007-12-31')
  }
  
    
  # town=towns[4]
  # for hunter make it newcastle
          if( town == "Lower Hunter"){
          town='Newcastle'
          }
  # town=towns[2]
  print(town)
  
  txt <- mindates_pollutant(town = town, pollutant = "pm10_av")
  mindatesp10 <- dbGetQuery(ch, txt)
  mindatesp10
  txt <- mindates_pollutant(town = town, pollutant = "pm25_av")
  mindatesp25 <- dbGetQuery(ch, txt)
  mindatesp25
  txt <- mindates_pollutant(town = town, pollutant = "o3_max")
  # and this one is seperate because it fails in towns without o3  
  mindateo3 <- dbGetQuery(ch, txt)
  mindateo3
   
  # TODO it would be nice to include a user interaction stage, where the start date could be modified  
  # Need to change for perth pm10 mindate because of duncraig monitoring station
  if(town == "PERTH"){
  mindatesp10[,2] <- as.Date('1997-05-23')
  }
  
  # in Launceston change pm10 mindate ="'1997-05-09'" changed from "'1992-05-04'" as this is start of consecutive day measurements prior to that it was weekly and seasonal
  if(town == "Launceston"){
  mindatesp10[,2] <- as.Date('1997-05-09')
  }
  
  #### PM10
  # max date is 2007, make a table with all dates 
  alldates_pm10_town  <- as.data.frame(as.Date(mindatesp10[,2]:maxdate_selected,'1970-01-01'))
  alldates_pm10_town$id <- 1:nrow(alldates_pm10_town)
  names(alldates_pm10_town) <- c('date','id')
  dbWriteTable(ch, paste('alldates_pm10_',tolower(town),sep=''), alldates_pm10_town, row.names = F)
  
  # make a table with every date at every station  
  txt <- all_stations_all_dates(town = town, pollutant = "pm10_av")
  #cat(txt)
  # try to be tidy
  try(
  dbSendQuery(ch,paste("drop table biosmoke_pollution.stationdates_",town,"_pm10;",sep=''))
  )
  dbSendQuery(ch, txt)
  dbSendQuery(ch,
  paste('drop table alldates_pm10_',town,sep='')
  )
  
  #### PM2.5
  # max date is 2007, make a table with all dates 
  alldates_pm25_town  <- as.data.frame(as.Date(mindatesp25[,2]:maxdate_selected,'1970-01-01'))
  alldates_pm25_town$id <- 1:nrow(alldates_pm25_town)
  names(alldates_pm25_town) <- c('date','id')
  dbWriteTable(ch, paste('alldates_pm25_',tolower(town),sep=''), alldates_pm25_town, row.names = F)
  
  # make a table with every date at every station  
  txt <- all_stations_all_dates(town = town, pollutant = "pm25_av")
  #cat(txt)
  # try to be tidy
  try(
  dbSendQuery(ch,paste("drop table biosmoke_pollution.stationdates_",town,"_pm25;",sep=''))
  )
  dbSendQuery(ch, txt)
  dbSendQuery(ch,
  paste('drop table alldates_pm25_',town,sep='')
  )
  
  #### O3
  # max date is 2007, make a table with all dates
  if(nrow(mindateo3) > 0){        
  alldates_o3_town  <- as.data.frame(as.Date(mindateo3[,2]:maxdate_selected,'1970-01-01'))
  alldates_o3_town$id <- 1:nrow(alldates_o3_town)
  names(alldates_o3_town) <- c('date','id')
  dbWriteTable(ch, paste('alldates_o3_',tolower(town),sep=''), alldates_o3_town, row.names = F)
  
  # make a table with every date at every station  
  txt <- all_stations_all_dates(town = town, pollutant = "o3_av")
  #cat(txt)
  # try to be tidy
  try(
  dbSendQuery(ch,paste("drop table biosmoke_pollution.stationdates_",town,"_o3;",sep=''))
  )
  dbSendQuery(ch, txt)
  dbSendQuery(ch,
  paste('drop table alldates_o3_',town,sep='')
  )
  }
          
  }
  
  
#+end_src

**** main missing dates-code
#+name:main missing dates
#+begin_src R :session *R* :tangle inst/doc/main.R :exports none :padline no :eval no
#### Do the processing
source("01_prepare_dates.R")
#+end_src

*** a lot of functions and a loop


**** R setup the mindates/polls/towns
#+begin_src R :session *R* :tangle inst/doc/main.R :exports none :padline no :eval no
  
  #### Set up a list of things to do in order ####
  todo=cbind(towns,rep('pm10',length(towns)),c("'1997-05-23'","'1994-01-01'","'1994-02-15'",
  "'1994-02-02'","'2006-04-22'" ,"'2001-05-01'"))
  
  todo=rbind(todo,cbind(towns,rep('pm25',length(towns)),c("'1994-02-15'","'1996-05-07'","'1998-03-01'" ,"'1996-06-19'","'2006-06-05'" ,"'2005-06-04'")))
  
  todo=rbind(todo,cbind(towns[1:4],rep('o3',4),rep("'1994-01-01'",4)))
  
  todo=as.data.frame(todo)
  todo
  todo$stat=ifelse(todo[,2]=='o3','max','av')
  todo
  
  i=8
  todo[i,]
  town=todo[i,1]
  poll=todo[i,2]
  mindate="'2003-01-01'"
    #todo[i,3]
  stat=todo[i,4]
     
#+end_src
**** view todo
          towns   V2           V3 stat
1         PERTH pm10 '1997-05-23'   av
2        Sydney pm10 '1994-01-01'   av
3     Illawarra pm10 '1994-02-15'   av
4  Lower Hunter pm10 '1994-02-02'   av
5        Hobart pm10 '2006-04-22'   av
6    Launceston pm10 '2001-05-01'   av
7         PERTH pm25 '1994-02-15'   av
8        Sydney pm25 '1996-05-07'   av
9     Illawarra pm25 '1998-03-01'   av
10 Lower Hunter pm25 '1996-06-19'   av
11       Hobart pm25 '2006-06-05'   av
12   Launceston pm25 '2005-06-04'   av
13        PERTH   o3 '1994-01-01'  max
14       Sydney   o3 '1994-01-01'  max
15    Illawarra   o3 '1994-01-01'  max
16 Lower Hunter   o3 '1994-01-01'  max

**** COMMENT func sites_todo-code
#+name:func sites_todo
#+begin_src R :session *R* :tangle R/sites_todo.R :exports none :padline no :eval yes
  #' @name sites_todo
  #' @title sites with potential
  #' @param town
  #' @param mindate
  #' @param maxdate
  #' @param threshold
  #' @param poll
  #' @param stat
  #' @return text for a sql query
  
  sites_todo <- function(town, mindate, maxdate="2007-12-31", threshold=0.7, poll, stat){
  
  print(poll);print(town)
  print(stat)
  # av or max?
  
  # find the stations with complete
  txt <- paste("
  select site,count,count(*) as potential, cast(count as numeric)/cast(count(*) as numeric) as complete
  from
          (
          select polls.* , valid.count,mindate.*
          from 
          (
                  (
                  SELECT biosmoke_pollution.stationdates_",town,"_",poll,".station as site, biosmoke_pollution.stationdates_",town,"_",poll,".date, ",poll,"_",stat," as param
                  FROM
                  biosmoke_pollution.stationdates_",town,"_",poll,"
                  left join
                  biosmoke_pollution.combined_pollutants
                  on biosmoke_pollution.stationdates_",town,"_",poll,".station=biosmoke_pollution.combined_pollutants.site
                  and biosmoke_pollution.stationdates_",town,"_",poll,".date=biosmoke_pollution.combined_pollutants.date
                  ) polls
          join 
                  (
                  SELECT biosmoke_pollution.stationdates_",town,"_",poll,".station as site, count(",poll,"_",stat,"), min(biosmoke_pollution.combined_pollutants.date)
                  FROM
                  biosmoke_pollution.stationdates_",town,"_",poll,"
                  left join
                  biosmoke_pollution.combined_pollutants
                  on biosmoke_pollution.stationdates_",town,"_",poll,".station=biosmoke_pollution.combined_pollutants.site
                  and biosmoke_pollution.stationdates_",town,"_",poll,".date=biosmoke_pollution.combined_pollutants.date
                  where ",poll,"_",stat," is not null and biosmoke_pollution.stationdates_",town,"_",poll,".date >= ",mindate,"
                                          and biosmoke_pollution.stationdates_",town,"_",poll,".date <= '",maxdate,"'
                  group by biosmoke_pollution.stationdates_",town,"_",poll,".station
                  ) valid
          on polls.site=valid.site
           
          ),
                  (
                  SELECT  min(biosmoke_pollution.combined_pollutants.date), max(biosmoke_pollution.combined_pollutants.date)
                  FROM
                  biosmoke_pollution.stationdates_",town,"_",poll,"
                  left join
                  biosmoke_pollution.combined_pollutants
                  on biosmoke_pollution.stationdates_",town,"_",poll,".station=biosmoke_pollution.combined_pollutants.site
                  and biosmoke_pollution.stationdates_",town,"_",poll,".date=biosmoke_pollution.combined_pollutants.date
                  where ",poll,"_",stat," is not null
                  ) mindate
          where polls.date >= ",mindate," and polls.date <= '",maxdate,"'
          order by polls.date
          ) foo
  group by site, count
  having cast(count as numeric)/cast(count(*) as numeric) >=",threshold,"
  ",sep="")
  
  # cat(txt)
  #d<- dbGetQuery(ch, txt)
  #sitelist <- d$site
  return(txt)
  }
  
  
#+end_src

#+RESULTS: func

**** R sites_todo
#+begin_src R :session *R* :tangle inst/doc/02_loop_over_stations_calculate_net_avg.R :exports none :padline no :eval no
  #### sites_todo
  txt <- sites_todo(town=town,mindate=mindate,poll=poll,stat=stat, maxdate = maxdate_selected)
  cat(txt)
  sitelist <- dbGetQuery(ch, txt)[,1]
  sitelist
  
#+end_src
**** COMMENT func impute
#+name:func sites_todo
#+begin_src R :session *R* :tangle R/impute.R :exports none :padline no :eval yes
  #' @name impute
  #' @title impute for each site
  #' @param sitelist sites
  #' @param town town
  #' @param poll pollutant
  #' @param stat statistical unit as per avg or max
  #' @param maxdate the end of the time series
  #' @return database table
  
  impute <- function(
    sitelist = c( "SouthLake", "Duncraig" )
    ,
    town = "PERTH"
    ,
    poll = "pm10"
    ,
    stat = "av"
    ,
    maxdate = "2007-12-31"
    ){
  
  # first make a table
  try(dbSendQuery(ch,
  # cat(
  paste("drop TABLE biosmoke_pollution.imputed_",poll,"_",town,sep='')
  ),silent=T)
  
  
  dbSendQuery(ch,
  # cat(
  paste("CREATE TABLE biosmoke_pollution.imputed_",poll,"_",town,"
  (
    site character varying(255),
    rawdate date,
    rawdata double precision,
    networkavg double precision,
    missingavg3mo double precision,
    networkavg3mo double precision,
    imputed double precision,
    imputed_param double precision
  )",sep="")
  )
  
  
  for(loc in sitelist[1:length(sitelist)]){
  # loc=sitelist[2]
  print(loc)
  
  # a) calculate a daily network average of all non-missing sites 
  txt <- paste("select date, avg(param) as networkavg         
  into biosmoke_pollution.networkavg
  from 
  (",
  paste("
  SELECT biosmoke_pollution.stationdates_",town,"_",poll,".station as site, biosmoke_pollution.stationdates_",town,"_",poll,".date, ",poll,"_",stat," as param
  FROM
  biosmoke_pollution.stationdates_",town,"_",poll,"
  left join
  biosmoke_pollution.combined_pollutants
  on biosmoke_pollution.stationdates_",town,"_",poll,".station=biosmoke_pollution.combined_pollutants.site
  and biosmoke_pollution.stationdates_",town,"_",poll,".date=biosmoke_pollution.combined_pollutants.date
  where biosmoke_pollution.stationdates_",town,"_",poll,".station = '",sitelist[-grep(loc,sitelist)],"'
                          and biosmoke_pollution.stationdates_",town,"_",poll,".date >= ",mindate," and biosmoke_pollution.stationdates_",town,"_",poll,".date <= '",maxdate,"'
  ",sep="",collapse="union"),
  ") t1
  where param is not null
  group by date
  order by date",sep="")
  
  #cat(txt)
  
  #strt=Sys.time()
  dbSendQuery(ch,txt)
  #endd=Sys.time()
  #print(endd-strt)
  
  # b) calculate a 3-month seasonal mean for this average of all non-missing sites
  
  # NB -45 and + 44 after reading the SAS CMOVAVE info as this is what it does when given an even number (90)
  txt <- "select t1.date, avg(t2.networkavg) as networkavg3mo          
  into biosmoke_pollution.networkavg3mo
  from
  biosmoke_pollution.networkavg t1,
  biosmoke_pollution.networkavg t2
  where (t2.date >= (t1.date -45) and t2.date <= (t1.date+44))
  group by t1.date 
  having count(t2.networkavg)>=(90*0.75)
  order by t1.date"
  
  #strt=Sys.time()
  dbSendQuery(ch,txt)
  #endd=Sys.time()
  #print(endd-strt)
  
  
  # c) calculate a 3-month seasonal mean for MISSING site
  
  txt <- paste("select t1.date, avg(t2.param) as missingavg3mo       
  into biosmoke_pollution.missingavg3mo
  from 
  (
  SELECT biosmoke_pollution.stationdates_",tolower(town),"_",poll,".station as site, biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date, ",poll,"_",stat," as param
  FROM
  biosmoke_pollution.stationdates_",tolower(town),"_",poll,"
  left join
  biosmoke_pollution.combined_pollutants
  on biosmoke_pollution.stationdates_",tolower(town),"_",poll,".station=biosmoke_pollution.combined_pollutants.site
  and biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date=biosmoke_pollution.combined_pollutants.date
  where biosmoke_pollution.stationdates_",tolower(town),"_",poll,".station = '",sitelist[grep(loc,sitelist)],"'
                          and biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date >= ",mindate," and biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date <= '",maxdate,"'
  ) t1,
  (
  SELECT biosmoke_pollution.stationdates_",tolower(town),"_",poll,".station as site, biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date, ",poll,"_",stat," as param
  FROM
  biosmoke_pollution.stationdates_",tolower(town),"_",poll,"
  left join
  biosmoke_pollution.combined_pollutants
  on biosmoke_pollution.stationdates_",tolower(town),"_",poll,".station=biosmoke_pollution.combined_pollutants.site
  and biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date=biosmoke_pollution.combined_pollutants.date
  where biosmoke_pollution.stationdates_",tolower(town),"_",poll,".station = '",sitelist[grep(loc,sitelist)],"'
                          and biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date >= ",mindate," and biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date <= '",maxdate,"'
  ) t2
  where (t2.date >= (t1.date -45) and t2.date <= (t1.date+44))
  group by t1.date 
  having count(t2.param)>=(90*0.75)",sep="")
  
  # cat(txt)
  strt=Sys.time()
  dbSendQuery(ch,txt)
  endd=Sys.time()
  print(endd-strt)
  
  # d) estimate missing days at missing sites and insert to output table
  txt <- paste("INSERT INTO  biosmoke_pollution.imputed_",poll,"_",tolower(town),"  (
              site, rawdate, rawdata, networkavg, missingavg3mo, networkavg3mo, 
              imputed, imputed_param
                                                  )
  select raw.site, raw.date as rawdate, param as rawdata, networkavg, missingavg3mo, networkavg3mo, 
              imputed, case when param is null then imputed else param end as imputed_param 
  from
  (
  SELECT biosmoke_pollution.stationdates_",tolower(town),"_",poll,".station as site, biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date, ",poll,"_",stat," as param
                  FROM
                  biosmoke_pollution.stationdates_",tolower(town),"_",poll,"
                  left join
                  biosmoke_pollution.combined_pollutants
                  on biosmoke_pollution.stationdates_",tolower(town),"_",poll,".station=biosmoke_pollution.combined_pollutants.site
                  and biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date=biosmoke_pollution.combined_pollutants.date
                                  where biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date >= ",mindate,"
                                          and biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date <= '",maxdate,"'
                                          and biosmoke_pollution.stationdates_",tolower(town),"_",poll,".station = '",loc,"'
  order by biosmoke_pollution.stationdates_",tolower(town),"_",poll,".date
  ) raw
  left join
  (
  select t1.date,
          t1.networkavg,
          t2.missingavg3mo,
          t3,networkavg3mo,
          t1.networkavg*(t2.missingavg3mo/t3.networkavg3mo) as imputed
  from ((biosmoke_pollution.networkavg t1
  join
          biosmoke_pollution.missingavg3mo t2
          on t1.date=t2.date)
  join
          biosmoke_pollution.networkavg3mo t3
          on t1.date=t3.date)
  order by t1.date
  ) imputed
  on raw.date=imputed.date
  order by raw.date
  ",sep="")
  
  #cat(txt)
  strt=Sys.time()
  dbSendQuery(ch,txt)              
  endd=Sys.time()
  print(endd-strt)
  
  
  dbSendQuery(ch,"drop table biosmoke_pollution.networkavg ;")
  dbSendQuery(ch,"drop table biosmoke_pollution.missingavg3mo;")
  dbSendQuery(ch,"drop table biosmoke_pollution.networkavg3mo;")
  
  }
  
  dbSendQuery(ch,
  # cat(
  paste("ALTER TABLE biosmoke_pollution.imputed_",poll,"_",town," rename rawdate to date",sep='')
  )
  
  }
  
  
#+end_src
**** R impute
#+begin_src R :session *R* :tangle inst/doc/02_loop_over_stations_calculate_net_avg.R :exports none :padline no :eval no
  impute(sitelist, town, poll, stat, maxdate = maxdate_selected)
  
#+end_src
**** R impute_aphea2
***** R-R impute_aphea2
#+name:R impute_aphea2
#+begin_src R :session *R* :tangle R/impute_aphea2.R :exports none :eval no
impute_aphea2 <- function(aqdf){

  library(dplyr);library(lubridate);library(tidyr)
  # making sure about date format
  aqdf$date <- dmy (aqdf$date)
  #making sure to have all the possible dates and sites
  sites <- unique(aqdf$site)
  dates <- seq (from = min(aqdf$date),
                to = max(aqdf$date),
                by = "day")
  date.site <- expand.grid(site = sites, date = dates)
  aqdf <- left_join(date.site,aqdf)
  aqdf <- aqdf %>% mutate (year = year(date))

  #average value at each site for each year
  df.year.site <- aqdf %>%
    group_by (year, site) %>%
    summarise_each (funs (mean(., na.rm = TRUE))) %>%
    select(-date) %>%
    ungroup()

  #average value for each year (across all sites)
  df.year <- aqdf %>%
    select(-site,-date) %>%
    group_by (year) %>%
    summarise_each (funs (mean(., na.rm = TRUE))) %>%
    ungroup()

  # repeating average yearly value for each site (just to calculate the ratio easily)
  years <- seq (from = min(aqdf$year),
                to = max(aqdf$year),
                by = 1)
  year.site <- expand.grid(year = years, site = sites)
  df.year <- left_join(year.site,df.year)

  # making sure that the year-site combination is exactly the same for both datasets
  df.year <- df.year %>% arrange (site, year)
  df.year.site <- df.year.site %>% arrange (site, year)

  #calculating the ratio of yearly value of each site to total
  df.ratio <- df.year.site [,3:ncol(df.year.site)] /
    df.year [,3:ncol(df.year)]
  df.ratio <- cbind (df.year.site [,1:2],df.ratio)

  # adding the dates (just repeating the ratio to cover the whole date)
  date.site.year <- date.site %>% mutate (year = year(date))
  df.ratio <- left_join(date.site.year,df.ratio)

  # calculating the average value of all sites for each day
  df.avg <- aqdf %>%
    select(-year,-site) %>%
    group_by (date) %>%
    summarise_each (funs (mean(., na.rm = TRUE))) %>%
    ungroup()

  # repeating the avg value to have it for all site and dates combination
  df.avg <- left_join(date.site.year,df.avg)

  # long formatting the airquality, average and ratio datasets
  df.aq.long <- gather (aqdf,
                            value = "concentration",
                            key = "pollutant", 3:(ncol(aqdf)-1))
  df.avg.long <- gather (df.avg,
                             value = "concentration",
                             key = "pollutant", 4:(ncol(df.avg)))
  df.ratio.long <- gather (df.ratio,
                               value = "concentration",
                               key = "pollutant", 4:(ncol(df.ratio)))

  # getting the sites, dates and pollutants with no value (NA)
  isna <- df.aq.long %>%
    filter (is.na(concentration)) %>%
    select(-concentration)

  # subsetting the avg and ratio datasets to the ones found in the previosu step
  df.avg.long.isna <- left_join(isna, df.avg.long)
  df.ratio.long.isna <- left_join(isna, df.ratio.long)

  # making sure the combinations are exactly in the same order
  df.avg.long.isna <- df.avg.long.isna %>% arrange (site,date,year)
  df.ratio.long.isna <- df.ratio.long.isna %>% arrange (site,date,year)

  # calculating the imputed value
  df.aq.imputed.isna <- data.frame(concentration =df.avg.long.isna[,5] * df.ratio.long.isna[,5])
  df.aq.imputed.isna <- cbind (df.avg.long.isna[,1:4],df.aq.imputed.isna)

  # getting the not NA values and binding them to the imputed ones
  df.aq.long.notna <- df.aq.long %>%
    filter (!is.na(concentration))
  df.aq.imputed.long <- rbind_list(df.aq.imputed.isna,df.aq.long.notna)

  # constructing the final dataframe
  df.aq.imputed <- spread(df.aq.imputed.long, key = pollutant, value = concentration)
  df.aq.imputed <- df.aq.imputed %>% select(-year)


  return(df.aq.imputed)
}

#+end_src
***** test-R impute_aphea2
#+name:R impute_aphea2
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:R impute_aphea2
  setwd("../..")
  dir()
  sydney <- read.csv (file = "data/sydney_pm25.csv")
  str(sydney)
  
  imputed_sydney <- impute_aphea2(sydney)
  str(imputed_sydney)
  head(imputed_sydney)
  imputed_sydney$date <-  as.Date(imputed_sydney$date, origin = '1970-01-01')
  imputed_sydney$date <-  as.character(imputed_sydney$date)
  names(imputed_sydney) <- gsub("\\.", "_", names(imputed_sydney))
  
  sydney$date <-  as.Date(sydney$date, format = '%d/%m/%Y')
  sydney$date <-  as.character(sydney$date)
  str(sydney)
  names(sydney) <- gsub("\\.", "_", names(sydney))
  
  mindate <- '1996-05-14' # '2004-01-04'
  sqldf::sqldf(drv="SQLite",
  sprintf("select t1.site, t1.date, t1.pm2_5, t2.pm2_5 as orig
  from imputed_sydney t1
  left join
  sydney t2
  on t1.site = t2.site and t1.date = t2.date
  where t1.site = 'earlwood' and t1.date <= '%s'
  ", mindate)
  )
  
  
  
#+end_src

**** COMMENT func n_missing
#+name:func sites_todo
#+begin_src R :session *R* :tangle R/n_missing.R :exports none :padline no :eval yes
  #' @name n_missing
  #' @title number missing
  #' @param town the one to do
  #' @param poll pollutant
  #' @param thresh theshold below which we will do it
  #' @return nmissing is a message like 'go for it'
  
  n_missing <- function(town,poll,thresh=0.05){
  
  nmissing<- dbGetQuery(ch,
  # cat(
  paste("
  select count(*) from
  (
  select 
   t1.date, avg(t2.",poll,") as citywide_",poll," , count(*)
  from
          (
          select date , avg(imputed_param) as ",poll,"
          from biosmoke_pollution.imputed_",poll,"_",town,"
          group by date
          having avg(imputed_param) is null
          ) t1,
          (
          select date , avg(imputed_param) as ",poll,"
          from biosmoke_pollution.imputed_",poll,"_",town,"
          group by date
          ) t2
  where (t2.date >= t1.date-1 and  t2.date <= t1.date+1)
  group by t1.date
  having count(t2.",poll,")>1
  order by t1.date
  ) foo
  ",sep="")
  )
  
  noverall<- dbGetQuery(ch,
  #cat(
  paste("select count(*) from
  (
  select date , avg(imputed_param) as ",poll,"
  from biosmoke_pollution.imputed_",poll,"_",town,"
  group by date
  ) bar",sep="")
  )
  
  if(nmissing/noverall<=thresh){"go for it"} else {"don't do the avg of the missing dates with before and after, too many"}
  
  }
  
  
  
#+end_src
**** R n_missing
#+begin_src R :session *R* :tangle inst/doc/02_loop_over_stations_calculate_net_avg.R :exports none :padline no :eval no
  # no avg all sites per day for city wide averages  
  # AND fill any missing days with avg of before and after (if this is less than 5% of days)
  # first make sure the number of missing days with one valid either side is < 5% of total days
  n_missing(town,poll)
  
  # if = 'go for it'
  
#+end_src
**** COMMENT func citywide_av
#+name:func sites_todo
#+begin_src R :session *R* :tangle R/citywide_av.R :exports none :padline no :eval yes
  #' @name citywide_av
  #' @title city wide average
  #' @param town
  #' @param poll
  #' @param stat
  #' @return nothing to R, this creates things in the database
  citywide_av <- function(town, poll, stat){
  
  # calculate and insert to temp table
  try(dbSendQuery(ch,
  #cat(
  paste("drop TABLE biosmoke_pollution.",poll,"_",stat,"_events_",town,"_temp",sep='')
  ),silent=T)
  
  dbSendQuery(ch,
  #cat(
  paste("CREATE TABLE biosmoke_pollution.",poll,"_",stat,"_events_",town,"_temp
  (
    date date NOT NULL,
    ",poll,"_",stat," numeric,
    ranked serial
  )",sep="")
  )
  
  dbSendQuery(ch,
  #cat(
  paste("
  INSERT INTO biosmoke_pollution.",poll,"_",stat,"_events_",town,"_temp (
      date, ",poll,"_",stat,")
  select citywide.date,
          case when citywide.",poll," is null then citywide_",poll," else ",poll," end as citywide_",poll,"
  from
          (
          select date , avg(imputed_param) as ",poll,"
          from biosmoke_pollution.imputed_",poll,"_",town,"
          group by date
          ) citywide
  left join
          (
          select 
                  t1.date, avg(t2.",poll,") as citywide_",poll," , count(*)
          from
                  (
                  select date , avg(imputed_param) as ",poll,"
                  from biosmoke_pollution.imputed_",poll,"_",town,"
                  group by date
                  having avg(imputed_param) is null
                  ) t1
          ,
                  (
                  select date , avg(imputed_param) as ",poll,"
                  from biosmoke_pollution.imputed_",poll,"_",town,"
                  group by date
                  ) t2
          where (t2.date >= t1.date-1 and  t2.date <= t1.date+1)
          group by t1.date
          having count(t2.",poll,")>1
          order by t1.date
          ) impute_missing_days
  on citywide.date=impute_missing_days.date
  where case when citywide.",poll," is null then citywide_",poll," else ",poll," end is not null
  order by case when citywide.",poll," is null then citywide_",poll," else ",poll," end
  ",sep="")
  )
  
  # ok calculate % and insert to output table
  try(dbSendQuery(ch,
  #cat(
  paste("drop TABLE biosmoke_pollution.",poll,"_",stat,"_events_",town,sep="")
  ),silent=T)
  
  
  
  dbSendQuery(ch,
  #cat(
  paste("CREATE TABLE biosmoke_pollution.",poll,"_",stat,"_events_",town,"
  (
    date date NOT NULL,
    ",poll,"_",stat," numeric,
    ranked numeric,
    pctile numeric
  )",sep="")
  )
  
  dbSendQuery(ch,
  #cat(
  paste("
  INSERT INTO biosmoke_pollution.",poll,"_",stat,"_events_",town," (
              date, ",poll,"_",stat,",ranked,pctile)
  select *, (cast(ranked as numeric)-1)/(
          (
          select count(*) from biosmoke_pollution.",poll,"_",stat,"_events_",town,"_temp
          ) 
  -1) as pctile
  from biosmoke_pollution.",poll,"_",stat,"_events_",town,"_temp",sep="")
  )
  
  }
  
#+end_src
**** R citywide_av
#+begin_src R :session *R* :tangle inst/doc/02_loop_over_stations_calculate_net_avg.R :exports none :padline no :eval no
  
  citywide_av(town,poll,stat)
#+end_src
**** R loop over all towns
#+begin_src R :session *R* :tangle inst/doc/02_loop_over_stations_calculate_net_avg.R :exports none :padline no :eval no
  for(i in 2:nrow(todo)){
  # i=15
  town=todo[i,1]
  if(town=="Lower Hunter"){
          town='Newcastle'
          } else {
          town=todo[i,1]
          }
  print(town)     
  poll=todo[i,2]
  print(poll)
  mindate=todo[i,3]
  print(mindate)
  stat=todo[i,4]
  print(stat)
  
  txt <- sites_todo(town=town,mindate=mindate,poll=poll,stat=stat, maxdate = maxdate_selected)
  sitelist <- dbGetQuery(ch, txt)[,1]
  #sitelist
  
  impute(sitelist, town, poll, stat, maxdate = maxdate_selected)
  
  
  nmissed=n_missing(town,poll)
  print(nmissed)
  if(nmissed=='go for it'){
          citywide_av(town,poll,stat)
          }
          
  }
#+end_src  
**** COMMENT func stitch_together
#+name:func sites_todo
#+begin_src R :session *R* :tangle R/stitch_together.R :exports none :padline no :eval yes
  #' @name stitch_together
  #' @title put all the bits together
  #' @param poll pollutant
  #' @param stat av or max
  #' @return tables in the database
  stitch_together <- function(poll=polls[5,3], stat = 'av'){
  
  print(poll)
  
  # NB only once!
  try(
  exist<- dbGetQuery(ch,
  #cat(
  paste("select * from biosmoke_pollution.",poll,"_",stat,"_events_all_regions limit 1",sep='')
  ), silent=T)
  
  if(length(nrow(exist))==0){
  
          dbSendQuery(ch,
          #cat(
          paste("CREATE TABLE biosmoke_pollution.",poll,"_",stat,"_events_all_regions
          (
            region text,
            date date NOT NULL,
            ",poll,"_",stat," numeric,
            ranked numeric,
            pctile numeric
          )",sep="")
          )
  
  }
  
  rm(exist)
  
  for(town in towns){
  if(town=="Lower Hunter"){
          town='Newcastle'
          }
  try(
  exist<- dbGetQuery(ch,
  #cat(
  paste("select * from biosmoke_pollution.",poll,"_",stat,"_events_",town," limit 1",sep='')
  ), silent=T)
  
  if(length(nrow(exist))>0){
          
          # dbSendQuery(ch,
          # # cat(
          # paste("delete from biosmoke_pollution.",poll,"_",stat,"_events_all_regions where region = \'",town,"\'",sep="")
          # )
  
          dbSendQuery(ch,
          # cat(
          paste("insert into biosmoke_pollution.",poll,"_",stat,"_events_all_regions (region, date, ",poll,"_",stat,", ranked, pctile)
          select '",town,"', date, ",poll,"_",stat,", ranked, pctile
          from  biosmoke_pollution.",poll,"_",stat,"_events_",town,sep="")
          )
  
  }
  rm(exist)
  
  }
  
  }
  
  
#+end_src
**** R stitch_together
#+begin_src R :session *R* :tangle inst/doc/02_loop_over_stations_calculate_net_avg.R :exports none :padline no :eval no
  
  stitch_together(poll="PM10", stat = "av")
  stitch_together(poll="PM25", stat = "av")
  stitch_together(poll="O3", stat = "max")
  dbSendQuery(ch,'grant all on table biosmoke_pollution.pm10_av_events_all_regions to biosmoke_user')   
  dbSendQuery(ch,'grant all on table biosmoke_pollution.pm25_av_events_all_regions to biosmoke_user')
  dbSendQuery(ch,'grant all on table biosmoke_pollution.o3_max_events_all_regions to biosmoke_user')
  
#+end_src

**** COMMENT R main-code
#+name:main
#+begin_src R :session *R* :tangle inst/doc/main.R :exports none :padline no :eval no
  maxdate_selected  <- "2014-12-31"
  source("02_loop_over_stations_calculate_net_avg.R")
  source("03_calc_extreme_events.R")
  # Now Manually validate events
  source("04_qc_checks.R")
  source("05_clean_up_intermediary_tables.R")
#+end_src
**** R clean up intermediary tables
#+begin_src R :session *R* :tangle inst/doc/05_clean_up_intermediary_tables.R :exports none :padline no :eval no
  
  # clean up
  
  dbSendQuery(ch,
  # cat(
  paste("drop table biosmoke_pollution.",'pm10',"_",c('av'),"_events_",gsub('Lower Hunter','Newcastle',towns),"_temp",sep='',collapse=';\n'))
  
  dbSendQuery(ch,
  # cat(
  paste("drop table biosmoke_pollution.",'pm25',"_",c('av'),"_events_",gsub('Lower Hunter','Newcastle',towns),"_temp",sep='',collapse=';\n'))
  
  dbSendQuery(ch,
  # cat(
  paste("drop table biosmoke_pollution.",'o3',"_",c('max'),"_events_",gsub('Lower Hunter','Newcastle',towns[1:4]),"_temp",sep='',collapse=';\n'))
  
  tbls <- pgListTables(ch, "biosmoke_pollution")
  tbls
  # to keep
  "
  4                combined_pollutants biosmoke_pollution
  52         o3_max_events_all_regions biosmoke_pollution
  53        pm10_av_events_all_regions biosmoke_pollution
  54        pm25_av_events_all_regions biosmoke_pollution
  3  pollution_stations_combined_final biosmoke_pollution
  "
  tbls <- read.table(textConnection("rowid                        relname            nspname
  48              imputed_o3_illawarra biosmoke_pollution
  50              imputed_o3_newcastle biosmoke_pollution
  44                  imputed_o3_perth biosmoke_pollution
  46                 imputed_o3_sydney biosmoke_pollution
  16               imputed_pm10_hobart biosmoke_pollution
  11            imputed_pm10_illawarra biosmoke_pollution
  18           imputed_pm10_launceston biosmoke_pollution
  14            imputed_pm10_newcastle biosmoke_pollution
  7                 imputed_pm10_perth biosmoke_pollution
  9                imputed_pm10_sydney biosmoke_pollution
  24               imputed_pm25_hobart biosmoke_pollution
  2             imputed_pm25_illawarra biosmoke_pollution
  26           imputed_pm25_launceston biosmoke_pollution
  6             imputed_pm25_newcastle biosmoke_pollution
  20                imputed_pm25_perth biosmoke_pollution
  22               imputed_pm25_sydney biosmoke_pollution
  49           o3_max_events_illawarra biosmoke_pollution
  51           o3_max_events_newcastle biosmoke_pollution
  45               o3_max_events_perth biosmoke_pollution
  47              o3_max_events_sydney biosmoke_pollution
  17             pm10_av_events_hobart biosmoke_pollution
  12          pm10_av_events_illawarra biosmoke_pollution
  19         pm10_av_events_launceston biosmoke_pollution
  15          pm10_av_events_newcastle biosmoke_pollution
  8               pm10_av_events_perth biosmoke_pollution
  10             pm10_av_events_sydney biosmoke_pollution
  25             pm25_av_events_hobart biosmoke_pollution
  5           pm25_av_events_illawarra biosmoke_pollution
  43         pm25_av_events_launceston biosmoke_pollution
  23          pm25_av_events_newcastle biosmoke_pollution
  21              pm25_av_events_perth biosmoke_pollution
  1              pm25_av_events_sydney biosmoke_pollution
  39          stationdates_hobart_pm10 biosmoke_pollution
  40          stationdates_hobart_pm25 biosmoke_pollution
  35         stationdates_illawarra_o3 biosmoke_pollution
  33       stationdates_illawarra_pm10 biosmoke_pollution
  34       stationdates_illawarra_pm25 biosmoke_pollution
  41      stationdates_launceston_pm10 biosmoke_pollution
  42      stationdates_launceston_pm25 biosmoke_pollution
  38         stationdates_newcastle_o3 biosmoke_pollution
  36       stationdates_newcastle_pm10 biosmoke_pollution
  37       stationdates_newcastle_pm25 biosmoke_pollution
  29             stationdates_perth_o3 biosmoke_pollution
  27           stationdates_perth_pm10 biosmoke_pollution
  28           stationdates_perth_pm25 biosmoke_pollution
  32            stationdates_sydney_o3 biosmoke_pollution
  30          stationdates_sydney_pm10 biosmoke_pollution
  31          stationdates_sydney_pm25 biosmoke_pollution
  "), header = T)
  
  head(tbls)
  
  for(i in 1:nrow(tbls)){
  #i = 1
    dbSendQuery(ch,
  #cat(
  paste("drop table biosmoke_pollution.",tbls$relnam[i],sep='')
    )
  
  }
  
#+end_src

**** R QC
#+begin_src R :session *R* :tangle inst/doc/04_qc_checks.R :exports none :padline no :eval no
  
  # TODO during tests I found there might be duplicated records for some
  # reason so check and rectify if so
  poll <- "o3_max" #"pm10_av" # "pm25_av" # #
  qc <- dbGetQuery(ch,
  paste("SELECT region, date,count(*)
   FROM biosmoke_pollution.",poll,"_events_all_regions
   group by region,date
    having count(*)>1", sep = "")
                   )
  head(qc)
  regiontest <- "Sydney"
  datetest <- "2002-04-07"
  dbGetQuery(ch,
  paste("select *
   FROM biosmoke_pollution.",poll,"_events_all_regions
   where region = '",regiontest,"' and date = '",datetest,"'
  ", sep = "")
  )
  # may have crept in via the station dates process?  
  
  
  
  ############################################################# 
  # summarise  
  
  # TODO: this needs to be looped thru todo rows so the mindate can be selected and missing days counted?
  
  descstats=data.frame(matrix(nrow=0,ncol=15))
  descstats
  for(i in 2:nrow(todo)){
  # i=1
  town=todo[i,1]
  if(town=="Lower Hunter"){
          town='Newcastle'
          } else {
          town=todo[i,1]
          }
  print(town)     
  poll=todo[i,2]
  print(poll)
  
  if(town=="PERTH" & poll=='pm25'){
  mindate=as.factor("'1994-03-01'")
          } else {
  mindate=todo[i,3]
          }
  
  
  
  print(mindate)
  stat=todo[i,4]
  print(stat)
  
  # town=towns[1]
  # print(town)   
          # dbSendQuery(ch,
          # # cat(
          # paste("delete from biosmoke_pollution.",poll,"_",stat,"_events_all_regions where region = \'",town,"\'",sep="")
          # )
  
  d<- dbGetQuery(ch,
          # cat(
          paste("select t1.date as fulldate, t2.*
          from  
          (select distinct date from biosmoke_pollution.stationdates_",town,"_",poll," where date >= ",mindate,") t1 
          left join 
          (select * from biosmoke_pollution.",poll,"_",stat,"_events_all_regions where region =\'",town,"\') as t2
          on t1.date=t2.date",sep="")
          )
          
  counts<- dbGetQuery(ch,
  # cat(
  paste("select \'99\', count(*)
  from
  (
  SELECT region, date, ",poll,"_",stat,", ranked, pctile
    FROM biosmoke_pollution.",poll,"_",stat,"_events_all_regions
    where region = \'",town,"\' and pctile >= .99
    ) foo
  union all
  select \'97-98\', count(*)
  from
  (
  SELECT region, date, ",poll,"_",stat,", ranked, pctile
    FROM biosmoke_pollution.",poll,"_",stat,"_events_all_regions
    where region = \'",town,"\'  and (pctile >= .97 and pctile < .99)
    ) foo
  union all
  select \'95-96\', count(*)
  from
  (
  SELECT region, date, ",poll,"_",stat,", ranked, pctile
    FROM biosmoke_pollution.",poll,"_",stat,"_events_all_regions
    where region = \'",town,"\'  and (pctile >= .95 and pctile < .97)
    ) foo
  union all
  select \'95+\', count(*)
  from
  (
  SELECT region, date, ",poll,"_",stat,", ranked, pctile
    FROM biosmoke_pollution.",poll,"_",stat,"_events_all_regions
    where region = \'",town,"\' and pctile >= .95
    ) foo;",sep="")
  )
          
  head(d)
  descstats=rbind(descstats,
  data.frame(t(c(as.character(town),
          paste(poll,stat),
          nrow(d),
          as.character(min(d$fulldate)),
          as.character(max(d$fulldate)),
          quantile(d[,4],.99,na.rm=T),
          quantile(d[,4],.97,na.rm=T),
          quantile(d[,4],.95,na.rm=T),
          counts[1,2],
          counts[2,2],
          counts[3,2],
          counts[4,2],
          t(
          if (length(names(summary(d[,4])))==6) {
          c(summary(d[,4]),NA)
          } else {
          summary(d[,4])
          }
          ))))
  )
  
  
  }
  
  names(descstats)=c('town','poll','numDays','mindate','maxdate','99','97','95','N99','N97_98','N95_96','N95',names(summary(d[,4])))
  descstats
  #write.csv(descstats,'descstats.csv',row.names=F)
  
  
  
  # I did some manual validation against the original files
  #M:\Environmental_Health\Bushfires\Exposures\TAS
  # etc
  # checked mindates, poll values, even if the single missing days were filled with av of prior and next.
  # for each in todo list.
  # all looks good.
  # only issue was perth mindate for pm2.5 which was no longer cavershamB 15/2/94 but now cavA 1/3/94
    
  # so this caveat is embedded in a if else in the descriptive stats above  
  
  
  #########################################################################################################
  # not changed is the underlying calculation of the percentiles as this would produce trivial changes to the percentile levels.
  ######################################################################################################### 
  
  ######################################################################################################### 
  # NB I did not double check the OZONE values.
  
  # useful code
  # select t1.date as fulldate, t2.*
  # from  
  # (select distinct date from biosmoke_pollution.stationdates_Sydney_pm10 where date >= '1994-01-10') t1 
  # left join 
  # (select * from biosmoke_pollution.pm10_av_events_all_regions where region ='Newcastle') as t2
  # on t1.date=t2.date
  
  
  # select *  
  # from  
  # (select distinct date from biosmoke_pollution.stationdates_illawarra_pm25 where date = '1998-03-01') t1 
  # left join 
  # (
  # select biosmoke_pollution.combined_pollutants.* 
  # from biosmoke_pollution.combined_pollutants 
  # join 
  # spatial.pollution_stations_combined_final
  # on
  # biosmoke_pollution.combined_pollutants.site=spatial.pollution_stations_combined_final.site 
  # where region = 'Illawara'
  # ) t2
  # on t1.date=t2.date
    
    
  
#+end_src
*** step4


**** TODO 03_calc_extreme_events.R
*** COMMENT 03_calc_extreme_events.R-code
**** R
#+name:03_calc_extreme_events.R
#+begin_src R :session *R* :tangle inst/doc/03_calc_extreme_events.R :exports none :eval no
  #### name:03_calc_extreme_events.R ####
  # now make a view for each poll so we can see what has been checked and what still needs to be checked
  
  for(poll in c("pm10_av", "pm25_av", "o3_max")){
  #poll = "pm10_av"
  txt <-  paste("
  create or replace view biosmoke_events.",poll,"_checked
  as 
  select ",poll,".region, ",poll,".date, cast(",poll,".pctile*100 as integer) as pctile, refid, eventid
  from
  biosmoke_pollution.",poll,"_events_all_regions as ",poll,"
  left join
  (
          SELECT t1.date, t2.*
          FROM 
                  biosmoke_pollution.",poll,"_events_all_regions t1
          ,
                  (
                  select tab1.*, 
                  case when place like 'Sydney%' then 'Sydney' else place end as region,
                  field3,field5, field7 from
                  biosmoke_events.tblevents tab1
                  join biosmoke_events.tblreferences tab2
                  on tab1.refid=tab2.refid
                  ) t2
          where t1.region=t2.region and 
                  (
                  t1.date=t2.mindate 
                  or
                  (t1.date >= t2.mindate and t1.date <= t2.maxdate)
                  )
  ) checked
  on ",poll,".date=checked.date
  and ",poll,".region=checked.region 
  where pctile>=.95 and mindate is not null 
    ORDER BY ",poll,".region, ",poll,".pctile DESC;
  grant select on biosmoke_events.",poll,"_checked to biosmoke_user;
  
  create or replace view biosmoke_events.",poll,"_to_check
  as 
  select ",poll,".region, ",poll,".date, cast(",poll,".pctile*100 as integer) as pctile, refid, eventid
  from
  biosmoke_pollution.",poll,"_events_all_regions as ",poll,"
  left join
  (
          SELECT t1.date, t2.*
          FROM 
                  biosmoke_pollution.",poll,"_events_all_regions t1
          ,
                  (
                  select tab1.*, 
                  case when place like 'Sydney%' then 'Sydney' else place end as region,
                  field3,field5, field7 from
                  biosmoke_events.tblevents tab1
                  join biosmoke_events.tblreferences tab2
                  on tab1.refid=tab2.refid
                  ) t2
          where t1.region=t2.region and 
                  (
                  t1.date=t2.mindate 
                  or
                  (t1.date >= t2.mindate and t1.date <= t2.maxdate)
                  )
  ) checked
  on ",poll,".date=checked.date
  and ",poll,".region=checked.region 
  where pctile>=.95 and mindate is null 
    ORDER BY ",poll,".region, ",poll,".pctile DESC;
  grant select on biosmoke_events.",poll,"_to_check to biosmoke_user
  ",sep="")
  
  cat(txt)
  dbSendQuery(ch, txt)
  }
#+end_src

**** COMMENT func QC missing99
#+name:func sites_todo
#+begin_src R :session *R* :tangle R/missing99.R :exports none :padline no :eval yes
  #' @name   missing99
  #' @title   99th centile missing references of any type
  #' @param poll pollutant
  #' @return list of dates
  missing99 <- function(poll){
  dat <- dbSendQuery(ch,
  # cat(
  paste("
  create or replace view biosmoke_pollution.",poll,"_to_check
  as 
  select ",poll,".*, eventid,refid, eventtype, place,mindate,maxdate, field3,field5, field7
  from
  biosmoke_pollution.",poll,"_av_events_all_regions as ",poll,"
  left join
  (
          SELECT t1.date, t2.*
          FROM 
                  biosmoke_pollution.",poll,"_",stat,"_events_all_regions t1
          ,
                  (
                  select tab1.*, 
                  case when place like 'Sydney%' then 'Sydney' else place end as region,
                  field3,field5, field7 from
                  ivan_hanigan.tblevents tab1
                  join ivan_hanigan.tblreferences tab2
                  on tab1.refid=tab2.refid
                  ) t2
          where t1.region=t2.region and 
                  (
                  t1.date=t2.mindate 
                  or
                  (t1.date >= t2.mindate and t1.date <= t2.maxdate)
                  )
  ) checked
  on ",poll,".date=checked.date
  and ",poll,".region=checked.region 
  where pctile>=.99 and mindate is null 
    ORDER BY ",poll,".region, ",poll,".pctile DESC;
  grant all on biosmoke_pollution.",poll,"_to_check to biosmoke_group
  ",sep="")
  )
  return(dat)
  }
  
  
  
#+end_src
**** R QC missing99
#+begin_src R :session *R* :tangle inst/doc/04_qc_checks.R :exports none :padline no :eval no
  # identify 99% centile days with no refs.
  missing99(poll=polls[5,3])
  missing99(poll=polls[7,3])

#+end_src

* COMMENT get-data-delphe-code
** get-data-delphe
#+begin_src R :session *R* :tangle no :exports none :padline no :eval no
  ################################################################
  # name:get-data-delphe
  require(rpostgrestools)
  setwd("~/projects/biomass_smoke_and_human_health/BiosmokeValidatedEvents/inst/extdata")
  ch <- connect2postgres2("delphe")
  
  tbls <- c("bio_events.tblreferences",
  "bio_events.tblevents",
  "bio_events.dust_event_records",
  "bio_events.dust_event_records2")
  dir()
  for(tb in tbls)
    {
      #tb  <- tbls[1]
      print(tb)
      df <- sql_subset(ch, tb, eval = T)
      #str(df)
      write.csv(df, paste(tb, ".csv", sep = ""), row.names = FALSE, na = "")
    }
  
#+end_src

** COMMENT load-data-ewedb_staging-code
#+name:load-data-ewedb
#+begin_src R :session *R* :tangle no :exports none :eval no
  #### name:load-data-ewedb ####
  require(rpostgrestools)
  setwd("~/projects/biomass_smoke_and_human_health/BiosmokeValidatedEvents/inst/extdata")
  dir()
  ch <- connect2postgres2("ewedb_staging")
  
  #### set up, actually did on pgadmin as postgres
  #dbSendQuery(ch,
  "
  
  CREATE TABLE biosmoke_events.tblreferences
  (
    refid serial NOT NULL,
    field1 text,
    field2 text,
    field3 text,
    field4 integer NOT NULL,
    field5 text,
    field6 text,
    field7 text NOT NULL,
    field8 text,
    field9 text,
    field10 integer,
    field11 text,
    field12 text,
    field13 text,
    field14 text,
    field15 text,
    field16 text,
    field17 text,
    field18 text,
    field19 text,
    field20 text,
    field21 text,
    field22 text,
    field23 text,
    field24 text,
    field25 text,
    field26 text,
    field27 text,
    field28 text,
    field29 text,
    field30 text,
    field31 text,
    field32 text,
    field33 text,
    field34 text,
    field35 text,
    field36 text,
    field37 text,
    field38 text,
    field39 text,
    field40 text,
    field41 text,
    CONSTRAINT biosmoke_events_tblreferences_pkey PRIMARY KEY (refid),
    CONSTRAINT biosmoke_events_credential_check CHECK (field28 = 'toms'::text OR field28 = 'government'::text OR field28 = 'journal'::text OR field28 = 'media'::text OR field28 = 'modis smoke'::text OR field28 = 'modis hotspot'::text OR field28 = 'internet'::text)
  )
  WITH (
    OIDS=FALSE
  );
  ALTER TABLE biosmoke_events.tblreferences
    OWNER TO postgres;
  GRANT ALL ON TABLE biosmoke_events.tblreferences TO ivan_hanigan;
  GRANT select ON TABLE biosmoke_events.tblreferences TO biosmoke_user;
  GRANT ALL ON sequence biosmoke_events.tblreferences_refid_seq TO ivan_hanigan;
  
  CREATE TABLE biosmoke_events.tblevents
  (
    eventid serial NOT NULL ,
    refid integer,
    eventid2 integer,
    eventtype character varying(255),
    place character varying(255) NOT NULL,
    mindate date NOT NULL,
    maxdate date,
    burnareaha character varying(255),
    metconditions character varying(255),
    CONSTRAINT biosmoke_events_tblevents_pkey PRIMARY KEY (eventid),
    CONSTRAINT biosmoke_events_tblref_cscd FOREIGN KEY (refid)
        REFERENCES biosmoke_events.tblreferences (refid) MATCH SIMPLE
        ON UPDATE CASCADE ON DELETE CASCADE,
    CONSTRAINT biosmoke_events_eventtype_check CHECK (eventtype::text = 'bushfire'::text OR eventtype::text = 'dust'::text OR eventtype::text = 'salt'::text OR eventtype::text = 'possible biomass'::text OR eventtype::text = 'prescribed burn'::text OR eventtype::text = 'woodsmoke'::text OR eventtype::text = 'non-biomass, fire'::text OR eventtype::text = 'non-biomass, non-fire'::text)
  )
  WITH (
    OIDS=FALSE
  );
  ALTER TABLE biosmoke_events.tblevents
    OWNER TO postgres;
  GRANT ALL ON TABLE biosmoke_events.tblevents TO ivan_hanigan;
  GRANT select ON TABLE biosmoke_events.tblevents TO biosmoke_user;
  GRANT ALL ON sequence biosmoke_events.tblevents_eventid_seq TO ivan_hanigan;
  
  "
  #            )
  
  
  
  
  #### load
  tbls <- c("bio_events.tblreferences",
  "bio_events.tblevents",
  "bio_events.dust_event_records",
  "bio_events.dust_event_records2")
  dir()
  #for(tb in tbls)
  #  {
  tb  <- tbls[2]
  print(tb)
   
  tbin <-    read.csv(paste(tb, ".csv", sep = ""), stringsAsFactor = FALSE)
      str(tbin)
  tbout <- gsub("bio_events.", "", tb)
  tbouttmp <- gsub("bio_events.", "temp", tb)
      tbouttmp
      dbWriteTable(ch, tbouttmp, tbin, row.names = F)
  
  
  #    dbSendQuery(ch, sprintf("insert into biosmoke_events.%s ()",
  #    tbout, tbouttmp))
  # done manually in pgadmin!
  
  dbRemoveTable(ch, tbouttmp)
  '
  # NB some break constraint of not null field28
  169;"IT Cental University of Tasmania";"";"http://home.iprimus.com.au/foo7/firesnsw.html"
  166;"IT Cental University of Tasmania";"";"http://home.iprimus.com.au/foo7/firesnsw.html"
  167;"IT Cental University of Tasmania";"";"http://home.iprimus.com.au/foo7/firesnsw.html"
  168;"IT Cental University of Tasmania";"";"http://home.iprimus.com.au/foo7/firesnsw.html"
  165;"IT Cental University of Tasmania";"";"http://home.iprimus.com.au/foo7/firesnsw.html"
  642;"bljkhg";"";""
  179;"aap australia general news";"";"http://www.highbeam.com/doc/1P1-104619075.html"
  180;"aap australian general news";"";"http://www.highbeam.com/doc/1P1-104619075.html"
  786;"EMA Disasters Database";"";"http://www.ema.gov.au/ema/emadisasters.nsf/54273a46a9c753b3ca256d0900180220/20b65e3cc204d21aca256d3300057db6?OpenDocument&Highlight=0,perth,bushfire,1997"
  
  So added as best could, added a value for internet, aap is media
  '
  #}
  
#+end_src

  
#+end_src
** COMMENT load-data-ewedb_prod-code
#+name:load-data-ewedb
#+begin_src R :session *R* :tangle no :exports none :eval no
# make sure remove server has schema and users as appropriate
pg_dump -h localhost -p 5432 -U postgres -i -n \"biosmoke_spatial\" ewedb_staging | psql -h gislibrary -U postgres ewedb
pg_dump -h localhost -p 5432 -U postgres -i -n \"biosmoke_pollution\" ewedb_staging | psql -h gislibrary -U postgres ewedb
pg_dump -h localhost -p 5432 -U postgres -i -n \"biosmoke_events\" ewedb_staging | psql -h gislibrary -U postgres ewedb


#+end_src
