#+TITLE:impute 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----
* Compared
** COMMENT compared-code
#+name:compared
#+begin_src R :session *shell* :tangle no :exports none :eval no
  #### name:compared ####
  # One archive is 
  dir1 <- "/media/external/ivan_acer/projects/1.302 Biomass/analysis/exposures/event validation"
  # the other is 
  dir2 <- "/media/external/u3171954-H/My Documents/projects/1.302 Biomass/analysis/exposures/event validation"
  
  dir(file.path(dir1, "metadata"))
  dir(dir2)
  
#+end_src
** found  
 After some considerable hunting I think this is the best workspace I have.      
 Physical Distribution:
 u3171954-H/My Documents/projects/1.302 Biomass/analysis/exposures/event validation/impute
** COMMENT load.r
#+name:loadw.r
#+begin_src R :session *shell* :tangle no :exports none :eval no
  #################################################################
  # I:/b_projects/1.302 Biomass/exposures/impute/workspace.R
  # author:
  # ihanigan
  # date:
  # 2009-10-27
  # description:
  # impute the biomass smoke pm
  #################################################################
  
  # changelog
  # 20100622      NOT DONE AS FOUND ALREADY IN DELPHE modified to put it back into delphe 
  # 20100407      changed to bio (post collapse) and calc perth, newc wollong
   
  require( RODBC )
  require( R2HTML )
  require(maptools)
  source('i:/tools/load2postgres.r')
  ch=odbcConnect("delphe")
  
  #################################################################
  # functions
  cleanup_shp=function(town){
          file.remove(paste(town,".shp",sep=""))
          file.remove(paste(town,".shx",sep=""))
          file.remove(paste(town,".dbf",sep=""))
          }
  #################################################################
  
  ## get city shapefile out for plotting in R
  towns=c("PERTH", "Sydney","Illawarra","Lower Hunter","Hobart","Launceston")
  
  
  ## this is messy, I haven't figured out how to feed the spatial data straight thru from postgres yet
  ## it has something to do with Rgdal and the driver on windows
  
  ## this workaround utilises the pgsql2shp tool that is installed with postgres
  
  # get the CCDs
  town=towns[2]
  #  for Illawarra  ='Wollongong' and Lower Hunter = 'Newcastle'
  #town='Newcastle'
  ste=1#5
  statenam='nsw'
  ## within urban boundary
  #sink("dopgshp.bat")
  #cat(paste("\"C:\\Program Files\\PostgreSQL\\8.3\\bin\\pgsql2shp\" -f \"",town,"\" -h 130.56.102.30 -u ivan_hanigan -P trojan9! weather \"select t1.* from abs_cd.",statenam,"cd06 t1, abs_ucl.ausucl01 t2 where st_contains(t2.the_geom,st_centroid(t1.the_geom)) and (t2.ste = ",ste," and upper(t2.ucl_name) like '",toupper(town),"%')\"",sep=""))
  #sink()
  ## or within distance
  sink("dopgshp.bat")
  cat(paste("\"C:\\Program Files\\PostgreSQL\\8.3\\bin\\pgsql2shp\" -f \"",town,"\" -h 130.56.102.30 -u ivan_hanigan -P trojan9! weather \"select t1.* from abs_sla.",statenam,"sla06 t1, abs_ucl.ausucl01 t2 where st_dwithin(st_centroid(t2.the_geom),st_centroid(t1.the_geom),0.5) and (t2.ste = ",ste," and upper(t2.ucl_name) like '",toupper(town),"%')\"",sep=""))
  sink()
  shell("dopgshp.bat")
  file.remove("dopgshp.bat")
  townshp = readShapePoly(paste(town,".shp",sep=""))
  
  town
  
  #townshp_perth=townshp
  townshp_sydney=townshp
  #townshp_illawarra=townshp
  #townshp_hunter=townshp
  
  cleanup_shp(town=town)
  
  plot(townshp, lwd=1, border="darkgrey")
  box();axis(1);axis(2)
  
  # now get the pollution stations
  town=towns[2]
  print(town)
  sink("dopgshp.bat")
  cat(paste("\"C:\\Program Files\\PostgreSQL\\8.3\\bin\\pgsql2shp\" -f \"",town,"\" -h db7.anu.edu.au -u ivan_hanigan -P trojan9! biomass \"select t1.*,t2.studysite as region2 from spatial.pollution_stations_combined_final t1 ,health.study_slas_01 t2 where st_intersects(t1.gda94_geom,t2.the_geom) and upper(region) like '",toupper(town),"%'\"",sep=""))
  sink()
  #
  shell("dopgshp.bat")
  file.remove("dopgshp.bat")
  sites=readShapePoints(paste(town,".shp",sep=""))
  cleanup_shp(town=town)
  
  town
  
  #sites_perth=sites
  sites_sydney=sites
  #sites_illawarra=sites
  #sites_hunter=sites
  
  sink("dopgshp.bat")
  cat(paste("\"C:\\Program Files\\PostgreSQL\\8.3\\bin\\pgsql2shp\" -f \"",town,"\" -h 130.56.102.30 -u ivan_hanigan -P trojan9! weather \"select * from public.oz_coast\"",sep=""))
  sink()
  #
  shell("dopgshp.bat")
  file.remove("dopgshp.bat")
  coast = readShapeSpatial(paste(town,".shp",sep=""))
  cleanup_shp(town=town)
  
  
  
  #################################################################
  
  # list pollutants
  polls=cbind(c("sulphurdioxide_pphm","nitrogendioxide_pphm","carbonmonoxide_ppm","ozone_pphm","particulatematter10um_ugm3","nephelometer_bsp", "particulatematter2_5um_ugm3", "nitricoxide_pphm"),
  c("hrlyso2","hrlyno2","hrlyco" ,    "hrlyo3", "hrlypm10", "hrlybsp",  "hrlypm25",  "hrlyno"),
  c("SO2","NO2","CO","O3","PM10","BSP","PM25","NO"))
  polls
  
  (poll=polls[4,3]) 
  
  #################################################################
  # to identify sites to be included need to know how many missing days.
  # first create complete set of statoiondates for the sites per town
  # this was set up after assessing the time series for completeness.  
  # Perth and Launceston PM10 mindates were altered 
  
  # note o3 only done for towns[1:4]
  # then just limit to [5] and so o3 fails, then [6] and o3 fails, allgood
  for(town in towns[4]){
  # town=towns[4]
  # for hunter make it newcastle
          if( town == "Lower Hunter"){
          town='Newcastle'
          }
  # town=towns[2]
  print(town)
  
  
  mindates=sqlQuery(ch,
  # cat(
  paste('select t1.r2, min(t1.date) as minpm10,min(t2.date) as minpm25
  from
  (SELECT  combined_pollutants2.r2, date,avg(pm10_av) as pm10_avg
          FROM pollution.combined_pollutants 
          join 
          (
                  select t1.site,t1.region as r2, t2.studysite as region
                  from spatial.pollution_stations_combined_final t1
  ,health.study_slas_01 t2
                  where st_intersects(t1.gda94_geom,t2.the_geom)
                          and lower(
        case when t2.studysite like \'Sydney%\' then \'Sydney\' else t2.studysite end 
        ) = \'',tolower(town),'\'
                  order by studysite
          ) combined_pollutants2 
          on
  (pollution.combined_pollutants.site=combined_pollutants2.site)
          where pm10_av is not null
          group by r2,date
          order by r2, date) t1
  ,
  (SELECT  combined_pollutants2.r2, date,avg(pm25_av) as pm25_avg
          FROM pollution.combined_pollutants 
          join 
          (
                  select t1.site,t1.region as r2, t2.studysite as region
                  from spatial.pollution_stations_combined_final t1
  ,health.study_slas_01 t2
                  where st_intersects(t1.gda94_geom,t2.the_geom)
                          and lower(
        case when t2.studysite like \'Sydney%\' then \'Sydney\' else t2.studysite end 
        ) = \'',tolower(town),'\'
                  order by studysite
          ) combined_pollutants2 
          on
  (pollution.combined_pollutants.site=combined_pollutants2.site)
          where pm25_av is not null 
          group by r2,date
          order by r2, date) t2
          group by t1.r2',sep='')
          )
  
  o3mindate=sqlQuery(ch,
  # cat(
  paste('select t1.r2, min(t1.date) as mino3_max
  from
  (SELECT  combined_pollutants2.r2, date,avg(o3_max) as o3_max
          FROM pollution.combined_pollutants 
          join 
          (
                  select t1.site,t1.region as r2, t2.studysite as region
                  from spatial.pollution_stations_combined_final t1
  ,health.study_slas_01 t2
                  where st_intersects(t1.gda94_geom,t2.the_geom)
                          and lower(
        case when t2.studysite like \'Sydney%\' then \'Sydney\' else t2.studysite end 
        ) = \'',tolower(town),'\'
                  order by studysite
          ) combined_pollutants2 
          on
  (pollution.combined_pollutants.site=combined_pollutants2.site)
          where o3_max is not null
          group by r2,date
          order by r2, date) t1
          group by t1.r2',sep='')
          )
          
  # for perth change pm10 mindate because of duncraig
  if( poll == 'PM10' & town == "PERTH"){
  mindates[,2]=as.Date('1997-05-23')
  }
  
  # in Launceston change pm10 mindate ="'1997-05-09'" changed from "'1992-05-04'" as this is start of consecutive day measurements 
  if( poll == 'PM10' & town == "Launceston"){
  mindates[,2]=as.Date('1997-05-09')
  }
  
  alldates_pm10_town=as.data.frame(as.Date(mindates[,2]:as.Date('2007-12-31'),'1970-01-01'))
  alldates_pm10_town$id=1:nrow(alldates_pm10_town)
  names(alldates_pm10_town)=c('date','id')
  write.csv(alldates_pm10_town,paste('alldates_pm10_',town,'.csv',sep=''),row.names=F,quote=F)
  load_newtable_to_postgres(paste('alldates_pm10_',town,'.csv',sep=''),schema='pollution',tablename=paste('alldates_pm10_',town,sep=''),pk=NULL,header=TRUE,printcopy=TRUE,sheetname="Sheet1",withoids=FALSE,pguser="ivan_hanigan",db='weather',ip='130.56.102.30',source_file="STDIN",datecol='date')
  
  
  
  #####################################################################
  # NOTE DONE, REALISED THIS IS IN DELPHE... modified to put it back into delphe 22/6/2010 after having changed to bio 7/4/2010 (post collapse)
  shell(paste("type sqlquery.txt \"alldates_pm10_",town,".csv\" | \"C:\\Program Files\\PostgreSQL\\8.3\\bin\\psql\" -h 130.56.102.30 -U ivan_hanigan -d bio",sep="")) 
  
  
  try(
  sqlQuery(ch,paste("drop table pollution.stationdates_",town,"_pm10;",sep=''))
  )
  sqlQuery(ch,
  #       cat(
          paste("
          select site as station, date 
          into pollution.stationdates_",town,"_pm10
          from
          (select distinct pollution.combined_pollutants.site 
          from pollution.combined_pollutants
          join
                  (
                  select t1.site,t2.studysite as region
                  from spatial.pollution_stations_combined_final t1 ,health.study_slas_01 t2
                  where st_intersects(t1.gda94_geom,t2.the_geom) and upper(t2.studysite) like '",toupper(town),"%'
                  order by studysite
                  ) combined_pollutants2
          on pollution.combined_pollutants.site=combined_pollutants2.site
          ) sites,
          (select * from pollution.alldates_pm10_",town,") dates
          ",sep="")
          )
  
  sqlQuery(ch,
  paste('drop table pollution.alldates_pm10_',town,sep='')
  )
  
  file.remove(paste('alldates_pm10_',town,'.csv',sep=''))
  
  #########################       
  alldates_pm25_town=as.data.frame(as.Date(mindates[,3]:as.Date('2007-12-31'),'1970-01-01'))
  alldates_pm25_town$id=1:nrow(alldates_pm25_town)
  names(alldates_pm25_town)=c('date','id')
  write.csv(alldates_pm25_town,paste('alldates_pm25_',town,'.csv',sep=''),row.names=F,quote=F)
  load_newtable_to_postgres(paste('alldates_pm25_',town,'.csv',sep=''),schema='pollution',tablename=paste('alldates_pm25_',town,sep=''),pk=NULL,header=TRUE,printcopy=TRUE,sheetname="Sheet1",withoids=FALSE,pguser="ivan_hanigan",db='weather',ip='130.56.102.30',source_file="STDIN",datecol='date')
  
  # modified to write to bio
  shell(paste("type sqlquery.txt \"alldates_pm25_",town,".csv\" | \"C:\\Program Files\\PostgreSQL\\8.3\\bin\\psql\" -h 130.56.102.30 -U ivan_hanigan -d bio",sep="")) 
  
  try(
  sqlQuery(ch,
  #       cat(
          paste("drop table pollution.stationdates_",town,"_pm25;",sep='')
          )
  )
  sqlQuery(ch,
  #       cat(
          paste("
          select site as station, date 
          into pollution.stationdates_",town,"_pm25
          from
          (select distinct pollution.combined_pollutants.site 
          from pollution.combined_pollutants
          join
                  (
                  select t1.site,t2.studysite as region
                  from spatial.pollution_stations_combined_final t1 ,health.study_slas_01 t2
                  where st_intersects(t1.gda94_geom,t2.the_geom) and upper(t2.studysite) like '",toupper(town),"%'
                  order by studysite
                  ) combined_pollutants2
          on pollution.combined_pollutants.site=combined_pollutants2.site
          ) sites,
          (select * from pollution.alldates_pm25_",town,") dates
          ",sep="")
          )
  
  sqlQuery(ch,
  paste('drop table pollution.alldates_pm25_',town,sep='')
  )
  
  file.remove(paste('alldates_pm25_',town,'.csv',sep=''))
  file.remove('sqlquery.txt')
  
  
  #########################       
  alldates_o3_town=as.data.frame(as.Date(o3mindate[,2]:as.Date('2007-12-31'),'1970-01-01'))
  alldates_o3_town$id=1:nrow(alldates_o3_town)
  names(alldates_o3_town)=c('date','id')
  write.csv(alldates_o3_town,paste('alldates_o3_',town,'.csv',sep=''),row.names=F,quote=F)
  load_newtable_to_postgres(paste('alldates_o3_',town,'.csv',sep=''),schema='pollution',tablename=paste('alldates_o3_',town,sep=''),pk=NULL,header=TRUE,printcopy=TRUE,sheetname="Sheet1",withoids=FALSE,pguser="ivan_hanigan",db='weather',ip='130.56.102.30',source_file="STDIN",datecol='date')
  
  
  # modified to write to bio
  shell(paste("type sqlquery.txt \"alldates_o3_",town,".csv\" | \"C:\\Program Files\\PostgreSQL\\8.3\\bin\\psql\" -h 130.56.102.30 -U ivan_hanigan -d bio",sep="")) 
  
  
  try(
  sqlQuery(ch,
  #       cat(
          paste("drop table pollution.stationdates_",town,"_o3;",sep="")
          )
  )
  sqlQuery(ch,
  #       cat(    
          paste("select site as station, date 
          into pollution.stationdates_",town,"_o3
          from
          (select distinct pollution.combined_pollutants.site 
          from pollution.combined_pollutants
          join
                  (
                  select t1.site,t2.studysite as region
                  from spatial.pollution_stations_combined_final t1 ,health.study_slas_01 t2
                  where st_intersects(t1.gda94_geom,t2.the_geom) and upper(t2.studysite) like '",toupper(town),"%'
                  order by studysite
                  ) combined_pollutants2
          on pollution.combined_pollutants.site=combined_pollutants2.site
          ) sites,
          (select * from pollution.alldates_o3_",town,") dates
          ",sep="")
          )
  
  sqlQuery(ch,
  paste('drop table pollution.alldates_o3_',town,sep='')
  )
  
  file.remove(paste('alldates_o3_',town,'.csv',sep=''))
  file.remove('sqlquery.txt')
  
  }
  
  
  
  
  save.image('impute.Rdata')
  
  
#+end_src
** COMMENT todo.r
#+name:todo.r
#+begin_src R :session *shell* :tangle no :exports none :eval no
  todo.r
  
  # to do
  require(RODBC)
  ch=odbcConnect('delphe')
  
  
  # perthPM10="'1997-05-23'"  (changed from 1996-06-15)
  # perthPM25="'1994-02-15'"   
  
  # sydneypm2.5="'1996-05-07'"
  # sydneypm10="'1994-01-01'"
  
  # illawarra only need to do ozone?  still needs missing days done
  # illawarraPM10="'1994-02-15'"
  # illawarraPM25="'1998-03-01'" 
  
  # newcastlepm2.5="'1996-06-19'"
  # Newcastle     PM10    ="'1994-02-02'"
  
  # hobart
  # hobart pm25="'2006-06-05'"
  # hobart pm10= "'2006-04-22'" 
  
  # launceston
  # mindate pm25="'2005-06-04'"
  # min pm10 ="'1997-05-09'" changed from "'1992-05-04'" as this is start of consecutive day measurements 
  # on 2010/04/14 I changed this again to the 1/5/2001 as this was the first year they went through the summer too
  
  towns
  todo=cbind(towns,rep('pm10',length(towns)),c("'1997-05-23'","'1994-01-01'","'1994-02-15'","'1994-02-02'","'2006-04-22'" ,"'2001-05-01'"))
  
  todo=rbind(todo,cbind(towns,rep('pm25',length(towns)),c("'1994-02-15'","'1996-05-07'","'1998-03-01'" ,"'1996-06-19'","'2006-06-05'" ,"'2005-06-04'")))
  
  todo=rbind(todo,cbind(towns[1:4],rep('o3',4),rep("'1994-01-01'",4)))
  
  
  todo=as.data.frame(todo)
  todo
  todo$stat=ifelse(todo[,2]=='o3','max','av')
  todo
  i=1
  town=todo[i,1]
  poll=todo[i,2]
  mindate=todo[i,3]
  stat=todo[i,4]
  
  # step one get a list of the sites to do
  sites_todo=function(town,mindate,maxdate="'2007-12-31'",threshold=0.7,poll,stat){
  
  print(poll);print(town)
  print(stat)
  # av or max?
  
  
  # find the stations with complete
  d=sqlQuery(ch,
  # writeClipboard(
  # cat(
  paste("
  select site,count,count(*) as potential, cast(count as numeric)/cast(count(*) as numeric) as complete
  from
          (
          select polls.* , valid.count,mindate.*
          from 
          (
                  (
                  SELECT pollution.stationdates_",town,"_",poll,".station as site, pollution.stationdates_",town,"_",poll,".date, ",poll,"_",stat," as param
                  FROM
                  pollution.stationdates_",town,"_",poll,"
                  left join
                  pollution.combined_pollutants
                  on pollution.stationdates_",town,"_",poll,".station=pollution.combined_pollutants.site
                  and pollution.stationdates_",town,"_",poll,".date=pollution.combined_pollutants.date
                  ) polls
          join 
                  (
                  SELECT pollution.stationdates_",town,"_",poll,".station as site, count(",poll,"_",stat,"), min(pollution.combined_pollutants.date)
                  FROM
                  pollution.stationdates_",town,"_",poll,"
                  left join
                  pollution.combined_pollutants
                  on pollution.stationdates_",town,"_",poll,".station=pollution.combined_pollutants.site
                  and pollution.stationdates_",town,"_",poll,".date=pollution.combined_pollutants.date
                  where ",poll,"_",stat," is not null and pollution.stationdates_",town,"_",poll,".date >= ",mindate,"
                                          and pollution.stationdates_",town,"_",poll,".date <= ",maxdate,"
                  group by pollution.stationdates_",town,"_",poll,".station
                  ) valid
          on polls.site=valid.site
           
          ),
                  (
                  SELECT  min(pollution.combined_pollutants.date), max(pollution.combined_pollutants.date)
                  FROM
                  pollution.stationdates_",town,"_",poll,"
                  left join
                  pollution.combined_pollutants
                  on pollution.stationdates_",town,"_",poll,".station=pollution.combined_pollutants.site
                  and pollution.stationdates_",town,"_",poll,".date=pollution.combined_pollutants.date
                  where ",poll,"_",stat," is not null
                  ) mindate
          where polls.date >= ",mindate," and polls.date <= ",maxdate,"
          order by polls.date
          ) foo
  group by site, count
  having cast(count as numeric)/cast(count(*) as numeric) >=",threshold,"
  ",sep="")
  )
  
  sitelist=d$site
  
  }
  # outputs sitelist
  
  # OK for these sites in turn.
   
                  # a) calculate a daily network average of all non-missing sites (ie without the focal station of the loop)
                  # b) calculate a 3-month seasonal mean for this average of all non-missing sites
                  # c) calculate a 3-month seasonal mean for MISSING site
                  # d) estimate missing days at missing sites
  
  # finally join all sites for city wide averages and fill any missing days with avg of before and after                  
  sitelist=sites_todo(town=town,mindate=mindate,poll=poll,stat=stat)
  sitelist
  
  impute=function(sitelist, town, poll, stat){
  
  # first make a table
  try(sqlQuery(ch,
  # cat(
  paste("drop TABLE pollution.imputed_",poll,"_",town,sep='')
  ),silent=T)
  
  
  sqlQuery(ch,
  # cat(
  paste("CREATE TABLE pollution.imputed_",poll,"_",town,"
  (
    site character varying(255),
    rawdate date,
    rawdata double precision,
    date date,
    networkavg double precision,
    missingavg3mo double precision,
    networkavg3mo double precision,
    imputed double precision,
    imputed_param double precision
  )",sep="")
  )
  
  
  for(loc in sitelist[1:length(sitelist)]){
  #loc=sitelist[1]
  print(loc)
  
  # a) calculate a daily network average of all non-missing sites 
  strt=Sys.time()
  sqlQuery(ch,
  # cat(
  paste("select date, avg(param) as networkavg         
  into pollution.networkavg
  from 
  (",
  paste("
  SELECT pollution.stationdates_",town,"_",poll,".station as site, pollution.stationdates_",town,"_",poll,".date, ",poll,"_",stat," as param
  FROM
  pollution.stationdates_",town,"_",poll,"
  left join
  pollution.combined_pollutants
  on pollution.stationdates_",town,"_",poll,".station=pollution.combined_pollutants.site
  and pollution.stationdates_",town,"_",poll,".date=pollution.combined_pollutants.date
  where pollution.stationdates_",town,"_",poll,".station = '",sitelist[-grep(loc,sitelist)],"'
                          and pollution.stationdates_",town,"_",poll,".date >= ",mindate," and pollution.stationdates_",town,"_",poll,".date <= ",maxdate,"
  ",sep="",collapse="union"),
  ") t1
  where param is not null
  group by date
  order by date",sep="")
  )
  endd=Sys.time()
  print(endd-strt)
  
  
  
  
  
  # b) calculate a 3-month seasonal mean for this average of all non-missing sites
  
  # NB -45 and + 44 after reading the SAS CMOVAVE info as this is what it does when given an even number (90)
  strt=Sys.time()
  sqlQuery(ch,
  "select t1.date, avg(t2.networkavg) as networkavg3mo          
  into pollution.networkavg3mo
  from
  pollution.networkavg t1,
  pollution.networkavg t2
  where (t2.date >= (t1.date -45) and t2.date <= (t1.date+44))
  group by t1.date 
  having count(t2.networkavg)>=(90*0.75)
  order by t1.date"
  )
  endd=Sys.time()
  print(endd-strt)
  
  
  # c) calculate a 3-month seasonal mean for MISSING site
  
  strt=Sys.time()
  sqlQuery(ch,
  # cat(
  paste("select t1.date, avg(t2.param) as missingavg3mo       
  into pollution.missingavg3mo
  from 
  (
  SELECT pollution.stationdates_",town,"_",poll,".station as site, pollution.stationdates_",town,"_",poll,".date, ",poll,"_",stat," as param
  FROM
  pollution.stationdates_",town,"_",poll,"
  left join
  pollution.combined_pollutants
  on pollution.stationdates_",town,"_",poll,".station=pollution.combined_pollutants.site
  and pollution.stationdates_",town,"_",poll,".date=pollution.combined_pollutants.date
  where pollution.stationdates_",town,"_",poll,".station = '",sitelist[grep(loc,sitelist)],"'
                          and pollution.stationdates_",town,"_",poll,".date >= ",mindate," and pollution.stationdates_",town,"_",poll,".date <= ",maxdate,"
  ) t1
  ,(
  SELECT pollution.stationdates_",town,"_",poll,".station as site, pollution.stationdates_",town,"_",poll,".date, ",poll,"_",stat," as param
  FROM
  pollution.stationdates_",town,"_",poll,"
  left join
  pollution.combined_pollutants
  on pollution.stationdates_",town,"_",poll,".station=pollution.combined_pollutants.site
  and pollution.stationdates_",town,"_",poll,".date=pollution.combined_pollutants.date
  where pollution.stationdates_",town,"_",poll,".station = '",sitelist[grep(loc,sitelist)],"'
                          and pollution.stationdates_",town,"_",poll,".date >= ",mindate," and pollution.stationdates_",town,"_",poll,".date <= ",maxdate,"
  ) t2
  where (t2.date >= (t1.date -45) and t2.date <= (t1.date+44))
  group by t1.date 
  having count(t2.param)>=(90*0.75)",sep="")
  )
  endd=Sys.time()
  print(endd-strt)
  
  
  
  
  
  # d) estimate missing days at missing sites and insert to output table
  strt=Sys.time()
  sqlQuery(ch,
  #cat(
  paste("INSERT INTO  pollution.imputed_",poll,"_",town,"  (
              site, rawdate, rawdata, date, networkavg, missingavg3mo, networkavg3mo, 
              imputed, imputed_param
                                                  )
  select raw.site, raw.date as rawdate, param as rawdata, imputed.date, networkavg, missingavg3mo, networkavg3mo, 
              imputed, case when param is null then imputed else param end as imputed_param 
  from
  (
  SELECT pollution.stationdates_",town,"_",poll,".station as site, pollution.stationdates_",town,"_",poll,".date, ",poll,"_",stat," as param
                  FROM
                  pollution.stationdates_",town,"_",poll,"
                  left join
                  pollution.combined_pollutants
                  on pollution.stationdates_",town,"_",poll,".station=pollution.combined_pollutants.site
                  and pollution.stationdates_",town,"_",poll,".date=pollution.combined_pollutants.date
                                  where pollution.stationdates_",town,"_",poll,".date >= ",mindate,"
                                          and pollution.stationdates_",town,"_",poll,".date <= ",maxdate,"
                                          and pollution.stationdates_",town,"_",poll,".station = '",loc,"'
  order by pollution.stationdates_",town,"_",poll,".date
  ) raw
  left join
  (
  select t1.date,
          t1.networkavg,
          t2.missingavg3mo,
          t3,networkavg3mo,
          t1.networkavg*(t2.missingavg3mo/t3.networkavg3mo) as imputed
  from ((pollution.networkavg t1
  join
          pollution.missingavg3mo t2
          on t1.date=t2.date)
  join
          pollution.networkavg3mo t3
          on t1.date=t3.date)
  order by t1.date
  ) imputed
  on raw.date=imputed.date
  order by raw.date
  ",sep="")
                  )
                  
  endd=Sys.time()
  print(endd-strt)
  
  
  sqlQuery(ch,"drop table pollution.networkavg ;")
  sqlQuery(ch,"drop table pollution.missingavg3mo;")
  sqlQuery(ch,"drop table pollution.networkavg3mo;")
  
  }
  
  }
  
  impute(sitelist, town, poll, stat)
  
  
  #################################################################################
  # finally avg all sites per day for city wide averages  
  # AND fill any missing days with avg of before and after (if this is less than 5% of days)
  # first make sure the number of missing days with one valid either side is < 5% of total days
  
  n_missing=function(town,poll,thresh=0.05){
  
  nmissing=sqlQuery(ch,
  # cat(
  paste("
  select count(*) from
  (
  select 
   t1.rawdate, avg(t2.",poll,") as citywide_",poll," , count(*)
  from
          (
          select rawdate , avg(imputed_param) as ",poll,"
          from pollution.imputed_",poll,"_",town,"
          group by rawdate
          having avg(imputed_param) is null
          ) t1
  ,
          (
          select rawdate , avg(imputed_param) as ",poll,"
          from pollution.imputed_",poll,"_",town,"
          group by rawdate
          ) t2
  where (t2.rawdate >= t1.rawdate-1 and  t2.rawdate <= t1.rawdate+1)
  group by t1.rawdate
  having count(t2.",poll,")>1
  order by t1.rawdate
  ) foo
  ",sep="")
  )
  
  noverall=sqlQuery(ch,
  paste("select count(*) from
  (
  select rawdate , avg(imputed_param) as ",poll,"
  from pollution.imputed_",poll,"_",town,"
  group by rawdate
  ) bar",sep="")
  )
  
  if(nmissing/noverall<=thresh){"go for it"} else {"don't do the avg of the missing dates with before and after, too many"}
  
  }
  
  n_missing(town,poll)
  
  # if = 'go for it'
  citywide_av=function(town, poll, stat){
  
  # calculate and insert to temp table
  try(sqlQuery(ch,
  #cat(
  paste("drop TABLE pollution.",poll,"_",stat,"_events_",town,"_temp",sep='')
  ),silent=T)
  
  sqlQuery(ch,
  #cat(
  paste("CREATE TABLE pollution.",poll,"_",stat,"_events_",town,"_temp
  (
    date date NOT NULL,
    ",poll,"_",stat," numeric,
    ranked serial
  )",sep="")
  )
  
  sqlQuery(ch,
  #cat(
  paste("
  INSERT INTO pollution.",poll,"_",stat,"_events_",town,"_temp (
      date, ",poll,"_",stat,")
  select citywide.rawdate,
          case when citywide.",poll," is null then citywide_",poll," else ",poll," end as citywide_",poll,"
  from
          (
          select rawdate , avg(imputed_param) as ",poll,"
          from pollution.imputed_",poll,"_",town,"
          group by rawdate
          ) citywide
  left join
          (
          select 
                  t1.rawdate, avg(t2.",poll,") as citywide_",poll," , count(*)
          from
                  (
                  select rawdate , avg(imputed_param) as ",poll,"
                  from pollution.imputed_",poll,"_",town,"
                  group by rawdate
                  having avg(imputed_param) is null
                  ) t1
          ,
                  (
                  select rawdate , avg(imputed_param) as ",poll,"
                  from pollution.imputed_",poll,"_",town,"
                  group by rawdate
                  ) t2
          where (t2.rawdate >= t1.rawdate-1 and  t2.rawdate <= t1.rawdate+1)
          group by t1.rawdate
          having count(t2.",poll,")>1
          order by t1.rawdate
          ) impute_missing_days
  on citywide.rawdate=impute_missing_days.rawdate
  where case when citywide.",poll," is null then citywide_",poll," else ",poll," end is not null
  order by case when citywide.",poll," is null then citywide_",poll," else ",poll," end
  ",sep="")
  )
  
  # ok calculate % and insert to output table
  sqlQuery(ch,
  #cat(
  paste("drop TABLE pollution.",poll,"_",stat,"_events_",town,sep="")
  )
  
  
  sqlQuery(ch,
  #cat(
  paste("CREATE TABLE pollution.",poll,"_",stat,"_events_",town,"
  (
    date date NOT NULL,
    ",poll,"_",stat," numeric,
    ranked numeric,
    pctile numeric
  )",sep="")
  )
  
  sqlQuery(ch,
  #cat(
  paste("
  INSERT INTO pollution.",poll,"_",stat,"_events_",town," (
              date, ",poll,"_",stat,",ranked,pctile)
  select *, (cast(ranked as numeric)-1)/(
          (
          select count(*) from pollution.",poll,"_",stat,"_events_",town,"_temp
          ) 
  -1) as pctile
  from pollution.",poll,"_",stat,"_events_",town,"_temp",sep="")
  )
  }
  
  citywide_av(town,poll,stat)
  
  # do all the other towns
  
  #################################################################################################################
  for(i in 2:nrow(todo)){
  # i=15
  town=todo[i,1]
  if(town=="Lower Hunter"){
          town='Newcastle'
          } else {
          town=todo[i,1]
          }
  print(town)     
  poll=todo[i,2]
  print(poll)
  mindate=todo[i,3]
  print(mindate)
  stat=todo[i,4]
  print(stat)
  
  sitelist=sites_todo(town=town,mindate=mindate,poll=poll,stat=stat)
  
  #sitelist
  
  impute(sitelist, town, poll, stat)
  
  
  nmissed=n_missing(town,poll)
  print(nmissed)
  if(nmissed=='go for it'){
          citywide_av(town,poll,stat)
          }
          
  }
  
  
  # clean up
  
  sqlQuery(ch,
  # cat(
  paste("drop table pollution.",'pm10',"_",c('av'),"_events_",gsub('Lower Hunter','Newcastle',towns),"_temp",sep='',collapse=';\n'))
  
  sqlQuery(ch,
  # cat(
  paste("drop table pollution.",'pm25',"_",c('av'),"_events_",gsub('Lower Hunter','Newcastle',towns),"_temp",sep='',collapse=';\n'))
  
  sqlQuery(ch,
  # cat(
  paste("drop table pollution.",'o3',"_",c('max'),"_events_",gsub('Lower Hunter','Newcastle',towns[1:4]),"_temp",sep='',collapse=';\n'))
  
  
  # create a master table
  stitch_together=function(poll=polls[5,3]){
  
  print(poll)
  
  # NB only once!
  
  exist=sqlQuery(ch,
  #cat(
  paste("select * from pollution.",poll,"_",stat,"_events_all_regions limit 1",sep='')
  )
  
  if(length(nrow(exist))==0){
  
          sqlQuery(ch,
          #cat(
          paste("CREATE TABLE pollution.",poll,"_",stat,"_events_all_regions
          (
            region text,
            date date NOT NULL,
            ",poll,"_",stat," numeric,
            ranked numeric,
            pctile numeric
          )",sep="")
          )
  
  }
  
  rm(exist)
  
  for(town in towns){
  if(town=="Lower Hunter"){
          town='Newcastle'
          }
          
          # sqlQuery(ch,
          # # cat(
          # paste("delete from pollution.",poll,"_",stat,"_events_all_regions where region = \'",town,"\'",sep="")
          # )
  
          sqlQuery(ch,
          # cat(
          paste("insert into pollution.",poll,"_",stat,"_events_all_regions (region, date, ",poll,"_",stat,", ranked, pctile)
          select '",town,"', date, ",poll,"_",stat,", ranked, pctile
          from  pollution.",poll,"_",stat,"_events_",town,sep="")
          )
  
  }
  
  }
  
  stitch_together(poll=polls[5,3])
  stitch_together(poll=polls[7,3])
  stitch_together(poll=polls[4,3])
  
  # check for duplicates
  # SELECT region, date,count(*)
    # FROM pollution.o3_max_events_all_regions
    # group by region,date
    # having count(*)>1
  
  # may have crept in via the station dates process?  
   
  sqlQuery(ch,'grant all on table pollution.pm10_av_events_all_regions to grant_williamson')
   
  sqlQuery(ch,'grant all on table pollution.pm25_av_events_all_regions to grant_williamson')
   
  sqlQuery(ch,'grant all on table pollution.o3_max_events_all_regions to grant_williamson')
  
  ############################################################# 
  # summarise  
  
  # TODO: this needs to be looped thru todo rows so the mindate can be selected and missing days counted?
  
  descstats=data.frame(matrix(nrow=0,ncol=15))
  descstats
  for(i in 1:nrow(todo)){
  # i=1
  town=todo[i,1]
  if(town=="Lower Hunter"){
          town='Newcastle'
          } else {
          town=todo[i,1]
          }
  print(town)     
  poll=todo[i,2]
  print(poll)
  
  if(town=="PERTH" & poll=='pm25'){
  mindate=as.factor("'1994-03-01'")
          } else {
  mindate=todo[i,3]
          }
  
  
  
  print(mindate)
  stat=todo[i,4]
  print(stat)
  
  # town=towns[1]
  # print(town)   
          # sqlQuery(ch,
          # # cat(
          # paste("delete from pollution.",poll,"_",stat,"_events_all_regions where region = \'",town,"\'",sep="")
          # )
  
  d=sqlQuery(ch,
          # cat(
          paste("select t1.date as fulldate, t2.*
          from  
          (select distinct date from pollution.stationdates_",town,"_",poll," where date >= ",mindate,") t1 
          left join 
          (select * from pollution.",poll,"_",stat,"_events_all_regions where region =\'",town,"\') as t2
          on t1.date=t2.date",sep="")
          )
          
  counts=sqlQuery(ch,
  # cat(
  paste("select \'99\', count(*)
  from
  (
  SELECT region, date, ",poll,"_",stat,", ranked, pctile
    FROM pollution.",poll,"_",stat,"_events_all_regions
    where region = \'",town,"\' and pctile >= .99
    ) foo
  union all
  select \'97-98\', count(*)
  from
  (
  SELECT region, date, ",poll,"_",stat,", ranked, pctile
    FROM pollution.",poll,"_",stat,"_events_all_regions
    where region = \'",town,"\'  and (pctile >= .97 and pctile < .99)
    ) foo
  union all
  select \'95-96\', count(*)
  from
  (
  SELECT region, date, ",poll,"_",stat,", ranked, pctile
    FROM pollution.",poll,"_",stat,"_events_all_regions
    where region = \'",town,"\'  and (pctile >= .95 and pctile < .97)
    ) foo
  union all
  select \'95+\', count(*)
  from
  (
  SELECT region, date, ",poll,"_",stat,", ranked, pctile
    FROM pollution.",poll,"_",stat,"_events_all_regions
    where region = \'",town,"\' and pctile >= .95
    ) foo;",sep="")
  )
          
  head(d)
  descstats=rbind(descstats,
  data.frame(t(c(as.character(town),
          paste(poll,stat),
          nrow(d),
          as.character(min(d$fulldate)),
          as.character(max(d$fulldate)),
          quantile(d[,4],.99,na.rm=T),
          quantile(d[,4],.97,na.rm=T),
          quantile(d[,4],.95,na.rm=T),
          counts[1,2],
          counts[2,2],
          counts[3,2],
          counts[4,2],
          t(
          if (length(names(summary(d[,4])))==6) {
          c(summary(d[,4]),NA)
          } else {
          summary(d[,4])
          }
          ))))
  )
  
  
  }
  
  names(descstats)=c('town','poll','numDays','mindate','maxdate','99','97','95','N99','N97_98','N95_96','N95',names(summary(d[,4])))
  descstats
  write.csv(descstats,'descstats.csv',row.names=F)
  
  
  
  # I did some manual validation against the original files
  #M:\Environmental_Health\Bushfires\Exposures\TAS
  # etc
  # checked mindates, poll values, even if the single missing days were filled with av of prior and next.
  # for each in todo list.
  # all looks good.
  # only issue was perth mindate for pm2.5 which was no longer cavershamB 15/2/94 but now cavA 1/3/94
    
  # so this caveat is embedded in a if else in the descriptive stats above  
  
  
  #########################################################################################################
  # not changed is the underlying calculation of the percentiles as this would produce trivial changes to the percentile levels.
  ######################################################################################################### 
  
  ######################################################################################################### 
  # NB I did not double check the OZONE values.
  
  # useful code
  # select t1.date as fulldate, t2.*
  # from  
  # (select distinct date from pollution.stationdates_Sydney_pm10 where date >= '1994-01-10') t1 
  # left join 
  # (select * from pollution.pm10_av_events_all_regions where region ='Newcastle') as t2
  # on t1.date=t2.date
  
  
  # select *  
  # from  
  # (select distinct date from pollution.stationdates_illawarra_pm25 where date = '1998-03-01') t1 
  # left join 
  # (
  # select pollution.combined_pollutants.* 
  # from pollution.combined_pollutants 
  # join 
  # spatial.pollution_stations_combined_final
  # on
  # pollution.combined_pollutants.site=spatial.pollution_stations_combined_final.site 
  # where region = 'Illawara'
  # ) t2
  # on t1.date=t2.date
    
    
    
  # identify 99% centile days with no refs.
  missing99=function(poll){
  sqlQuery(ch,
  # cat(
  paste("
  create or replace view pollution.",poll,"_to_check
  as 
  select ",poll,".*, eventid,refid, eventtype, place,mindate,maxdate, field3,field5, field7
  from
  pollution.",poll,"_av_events_all_regions as ",poll,"
  left join
  (
          SELECT t1.date, t2.*
          FROM 
                  pollution.",poll,"_",stat,"_events_all_regions t1
          ,
                  (
                  select tab1.*, 
                  case when place like 'Sydney%' then 'Sydney' else place end as region,
                  field3,field5, field7 from
                  ivan_hanigan.tblevents tab1
                  join ivan_hanigan.tblreferences tab2
                  on tab1.refid=tab2.refid
                  ) t2
          where t1.region=t2.region and 
                  (
                  t1.date=t2.mindate 
                  or
                  (t1.date >= t2.mindate and t1.date <= t2.maxdate)
                  )
  ) checked
  on ",poll,".date=checked.date
  and ",poll,".region=checked.region 
  where pctile>=.99 and mindate is null 
    ORDER BY ",poll,".region, ",poll,".pctile DESC;
  grant all on pollution.",poll,"_to_check to grant_williamson
  ",sep="")
  )
  
  }
  
  missing99(poll=polls[5,3])
  missing99(poll=polls[7,3])
  
#+end_src
** also see summary stats
head/projects/Biomass/data/pollution/summaryValidPollution4events
I:\Dropbox\projects\1.302 Biomass\data\pollution\summaryValidPollution4events
